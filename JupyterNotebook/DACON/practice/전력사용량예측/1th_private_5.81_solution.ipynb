{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://dacon.io/competitions/official/236125/codeshare/8776?page=1&dtype=tag&fType=&category=codeshare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Linux version: 5.15.120+\n",
    "- Python version: 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:40:32) [GCC 12.3.0]\n",
    "- xgboost version: 1.7.6\n",
    "- pandas version: 1.5.3\n",
    "- numpy version: 1.23.5\n",
    "- optuna version: 3.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-09-01T03:37:20.972372Z",
     "iopub.status.busy": "2023-09-01T03:37:20.972023Z",
     "iopub.status.idle": "2023-09-01T03:37:35.437970Z",
     "shell.execute_reply": "2023-09-01T03:37:35.437252Z",
     "shell.execute_reply.started": "2023-09-01T03:37:20.972345Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linux version: 5.15.120+\n",
      "Python version: 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:40:32) [GCC 12.3.0]\n",
      "xgboost version: 1.7.6\n",
      "pandas version: 1.5.3\n",
      "numpy version: 1.23.5\n",
      "optuna version: 3.2.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!pip install -q sktime\n",
    "from tqdm import tqdm\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import math\n",
    "import os\n",
    "from xgboost import XGBRegressor\n",
    "import platform\n",
    "import optuna\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "\n",
    "if platform.system() == \"Linux\":\n",
    "    linux_version = platform.uname().release\n",
    "    print(\"Linux version:\", linux_version)\n",
    "    \n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"xgboost version:\", xgb.__version__)\n",
    "print(\"pandas version:\", pd.__version__)\n",
    "print(\"numpy version:\", np.__version__)\n",
    "print(\"optuna version:\", optuna.__version__)\n",
    "\n",
    "base_path = '/kaggle/input/big-one'\n",
    "\n",
    "def SMAPE(true, pred):\n",
    "    return np.mean((np.abs(true-pred))/(np.abs(true) + np.abs(pred))) * 200\n",
    "\n",
    "def weighted_mse(alpha = 1):\n",
    "    def weighted_mse_fixed(label, pred):\n",
    "        residual = (label - pred).astype(\"float\")\n",
    "        grad = np.where(residual>0, -2*alpha*residual, -2*residual)\n",
    "        hess = np.where(residual>0, 2*alpha, 2.0)\n",
    "        return grad, hess\n",
    "    return weighted_mse_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T03:37:35.440007Z",
     "iopub.status.busy": "2023-09-01T03:37:35.439642Z",
     "iopub.status.idle": "2023-09-01T03:37:35.489578Z",
     "shell.execute_reply": "2023-09-01T03:37:35.488516Z",
     "shell.execute_reply.started": "2023-09-01T03:37:35.439985Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_data(df):\n",
    "    for i in range(2):\n",
    "        np.random.seed(i)\n",
    "        num_rows = len(df)\n",
    "        random_factors = ['temp', 'prec', 'wind', 'hum']\n",
    "\n",
    "        random_data = {\n",
    "            factor: df[factor] * np.random.uniform(0.9, 1.1, num_rows)\n",
    "            for factor in random_factors\n",
    "        }\n",
    "\n",
    "        random_data = {factor: np.round(data, 1) for factor, data in random_data.items()}\n",
    "\n",
    "        new_df = df.copy()\n",
    "        new_df.update(pd.DataFrame(random_data))\n",
    "        df = pd.concat([df, new_df], ignore_index=True)\n",
    "\n",
    "    df = df.sort_values(by=['building', 'date_time']).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def weather(train):\n",
    "    condition = train['prec'] > 0\n",
    "    filtered_df = train[condition].index.tolist()\n",
    "    train['weather'] = 0\n",
    "\n",
    "    for idx in filtered_df:\n",
    "        for offset in range(-3, 4):\n",
    "            new_idx = idx + offset\n",
    "            if 0 <= new_idx < len(train):\n",
    "                train.loc[new_idx, 'weather'] = 1\n",
    "\n",
    "    return train\n",
    "\n",
    "def time_features(data, mode):\n",
    "    date = pd.to_datetime(data.date_time)\n",
    "    \n",
    "    data['hour'] = date.dt.hour\n",
    "    data['dow'] = date.dt.weekday\n",
    "    data['month'] = date.dt.month\n",
    "    data['week'] = date.dt.isocalendar().week.astype(np.int32)\n",
    "    data['day'] = date.dt.day\n",
    "\n",
    "    data['sin_time'] = np.sin(2 * np.pi * data['hour'] / 24)\n",
    "    data['cos_time'] = np.cos(2 * np.pi * data['hour'] / 24)\n",
    "    \n",
    "    data['holiday'] = data.apply(lambda x : 0 if x['dow'] < 5 else 1, axis = 1)\n",
    "    data['date'] = pd.to_datetime(data['date_time'], format='%Y-%m-%d').dt.date\n",
    "    \n",
    "    building_dates = [['2022-06-07', '2022-06-17'], ['2022-07-31', '2022-07-23', '2022-07-20'], ['2022-08-16', '2022-08-17']]\n",
    "    \n",
    "    for index, b in enumerate([2, 3 ,54]):\n",
    "        data.loc[data['building'] == b, 'holiday'] = 0\n",
    "        data.loc[(data['building'] == b) & (data['dow'] == 0) , 'holiday'] = 1\n",
    "        data.loc[(data['building'] == b) & (data['date'].isin([pd.to_datetime(i).date() for i in building_dates[index]])), 'holiday'] = 1\n",
    "    \n",
    "    data.loc[(data['building'] != 14) & (data['date'].isin([pd.to_datetime(i).date() for i in ['2022-06-01', '2022-06-06', '2022-08-15']])), 'holiday'] = 1\n",
    "    data.loc[(data['building'] == 14) & (data['date'].isin([pd.to_datetime(i).date() for i in ['2022-06-14']])) , 'holiday'] = 1\n",
    "    data.loc[data['building'] == 85, 'holiday'] = 0\n",
    "    \n",
    "    def week_of_month(date):\n",
    "        first_day = date.replace(day=1)\n",
    "        if (date.isocalendar().week - first_day.isocalendar().week + 1) % 2 == 0:\n",
    "            if date.weekday() == 6:\n",
    "                return 1\n",
    "        return 0\n",
    "\n",
    "    data['week_of_month'] = data['date'].apply(week_of_month)\n",
    "\n",
    "    target_buildings = [87,88,89,90,91,92]\n",
    "    data.loc[(data['building'].isin(target_buildings)) , 'holiday'] = 0\n",
    "    data.loc[(data['building'].isin(target_buildings)) & (data['week_of_month'] == 1), 'holiday'] = 1\n",
    "    \n",
    "    building_dates = [['2022-06-20', '2022-07-11', '2022-08-08', '2022-06-17'], ['2022-06-13', '2022-07-25', '2022-08-01'],\n",
    "                     ['2022-07-18', '2022-08-08'], ['2022-06-20', '2022-07-18', '2022-06-17', '2022-08-08'],\n",
    "                     ['2022-06-27', '2022-07-25', '2022-08-08'], ['2022-06-13', '2022-07-11', '2022-08-22'],\n",
    "                     ['2022-06-10', '2022-08-10', '2022-07-10', '2022-07-24', '2022-06-26', '2022-08-28']]\n",
    "    if mode == 'byb' or mode == 'gu_byb':\n",
    "        for index, b in enumerate([37,38,39,40,41,42,86]):\n",
    "            data.loc[data['building'] == b, 'holiday'] = 0\n",
    "            data.loc[(data['building'] == b) & (data['date'].isin([pd.to_datetime(i).date() for i in building_dates[index]])), 'holiday'] = 1\n",
    "            \n",
    "    if mode == 'all' or mode == 'gu_all':\n",
    "        data.loc[data['building'] == 86, 'holiday'] = 0\n",
    "        data.loc[(data['building'] == 86) & (data['date'].isin([pd.to_datetime(i).date() for i in building_dates[-1]+['2022-07-30']])), 'holiday'] = 1\n",
    "    \n",
    "    data['date'] = pd.to_datetime(data['date_time'], format='%Y-%m-%d')\n",
    "    return data\n",
    "\n",
    "def side_indicator(data):\n",
    "    data['THI'] = 9/5*data['temp'] - 0.55*(1-data['hum']/100)*(9/5*data['hum']-26)+32\n",
    "    data['WC']=13.12+0.6215*data['temp']-13.947*data['wind']**0.16+0.486*data['temp']*data['wind']**0.16\n",
    "    \n",
    "    def calculate_cdh(xs):\n",
    "        ys = []\n",
    "        for i in range(len(xs)):\n",
    "            if i < 11:\n",
    "                ys.append(np.sum(xs[:(i+1)] - 26))\n",
    "            else:\n",
    "                ys.append(np.sum(xs[(i-11):(i+1)] - 26))\n",
    "        return np.array(ys)\n",
    "\n",
    "    cdhs = []\n",
    "    for num in range(1, 101):\n",
    "        temp = data[data['building'] == num]\n",
    "        cdh = calculate_cdh(temp['temp'].values)\n",
    "        cdhs.extend(cdh)\n",
    "    data['CDH'] = cdhs\n",
    "\n",
    "    return data\n",
    "    \n",
    "def summer_cos(date):\n",
    "    start_date = datetime.strptime(\"2022-06-01 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "    end_date = datetime.strptime(\"2022-09-14 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    period = (end_date - start_date).total_seconds()\n",
    "\n",
    "    return math.cos(2 * math.pi * (date - start_date).total_seconds() / period)\n",
    "\n",
    "def summer_sin(date):\n",
    "    start_date = datetime.strptime(\"2022-06-01 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "    end_date = datetime.strptime(\"2022-09-14 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    period = (end_date - start_date).total_seconds()\n",
    "\n",
    "    return math.sin(2 * math.pi * (date - start_date).total_seconds() / period)\n",
    "\n",
    "def temp_features(data):\n",
    "    avg_temp = pd.pivot_table(data[data['hour']%3 == 0], values = 'temp', index = ['building', 'day', 'month'], aggfunc = np.mean).reset_index()\n",
    "    avg_temp.rename(columns={'temp': 'avg_temp'}, inplace=True)\n",
    "    data = pd.merge(data, avg_temp, on=['building', 'day', 'month'], how='left')\n",
    "    \n",
    "    max_temp = pd.pivot_table(data, values = 'temp', index = ['building', 'day', 'month'], aggfunc = np.max).reset_index()\n",
    "    max_temp.rename(columns={'temp': 'max_temp'}, inplace=True)\n",
    "    data = pd.merge(data, max_temp, on=['building', 'day', 'month'], how='left')\n",
    "    \n",
    "    min_temp = pd.pivot_table(data, values = 'temp', index = ['building', 'day', 'month'], aggfunc = np.min).reset_index()\n",
    "    min_temp.rename(columns={'temp': 'min_temp'}, inplace=True)\n",
    "    data = pd.merge(data, min_temp, on=['building', 'day', 'month'], how='left')\n",
    "    \n",
    "    data['temp_diff'] = data['max_temp'] - data['min_temp']\n",
    "    \n",
    "    return data\n",
    "    \n",
    "def process_data(data, mode):\n",
    "    data['wind'] = data['wind'].fillna(method='ffill')\n",
    "    data['hum'] = data['hum'].fillna(method='ffill')\n",
    "    data = data.fillna(0)\n",
    "\n",
    "    data = time_features(data, mode)\n",
    "    data = side_indicator(data)\n",
    "    data = temp_features(data)\n",
    "    \n",
    "    data['summer_cos'] = data['date'].apply(summer_cos)\n",
    "    data['summer_sin'] = data['date'].apply(summer_sin)\n",
    "\n",
    "    return data\n",
    "\n",
    "def mean_std(train, test, mode):\n",
    "    ratio = np.array([0.985]+[0.98]*2+[0.995]*2+[0.99]*2)\n",
    "    if mode == 'byb':\n",
    "        train['target'] = train.apply(lambda row: row['target'] * ratio[row['dow']], axis=1)\n",
    "    elif mode == 'all':\n",
    "        ratio -= 0.005\n",
    "        train['target'] = train.apply(lambda row: row['target'] * ratio[row['dow']], axis=1)\n",
    "    \n",
    "    power_mean = pd.pivot_table(train, values = 'target', index = ['building', 'hour', 'dow'], aggfunc = np.mean).reset_index()\n",
    "    power_mean.rename(columns={'target': 'dow_hour_mean'}, inplace=True)\n",
    "    train = pd.merge(train, power_mean, on=['building', 'hour', 'dow'], how='left')\n",
    "    test = pd.merge(test, power_mean, on=['building', 'hour', 'dow'], how='left')\n",
    "    \n",
    "    power_holiday_mean = pd.pivot_table(train, values = 'target', index = ['building', 'hour', 'holiday'], aggfunc = np.mean).reset_index()\n",
    "    power_holiday_mean.rename(columns={'target': 'holiday_mean'}, inplace=True)\n",
    "    train = pd.merge(train, power_holiday_mean, on=['building', 'hour', 'holiday'], how='left')\n",
    "    test = pd.merge(test, power_holiday_mean, on=['building', 'hour', 'holiday'], how='left')\n",
    "\n",
    "    power_holiday_std = pd.pivot_table(train, values = 'target', index = ['building', 'hour', 'holiday'], aggfunc = np.std).reset_index()\n",
    "    power_holiday_std.rename(columns={'target': 'holiday_std'}, inplace=True)\n",
    "    train = pd.merge(train, power_holiday_std, on=['building', 'hour', 'holiday'], how='left')\n",
    "    test = pd.merge(test, power_holiday_std, on=['building', 'hour', 'holiday'], how='left')\n",
    "\n",
    "    power_hour_mean = pd.pivot_table(train, values = 'target', index = ['building', 'hour',], aggfunc = np.mean).reset_index()\n",
    "    power_hour_mean.rename(columns={'target': 'hour_mean'}, inplace=True)\n",
    "    train = pd.merge(train, power_hour_mean, on=['building', 'hour', ], how='left')\n",
    "    test = pd.merge(test, power_hour_mean, on=['building', 'hour', ], how='left')\n",
    "\n",
    "    power_hour_std = pd.pivot_table(train, values = 'target', index = ['building', 'hour',], aggfunc = np.std).reset_index()\n",
    "    power_hour_std.rename(columns={'target': 'hour_std'}, inplace=True)\n",
    "    train = pd.merge(train, power_hour_std, on=['building', 'hour', ], how='left')\n",
    "    test = pd.merge(test, power_hour_std, on=['building', 'hour', ], how='left')\n",
    "    \n",
    "    if mode == 'all' or mode == 'gu_all':\n",
    "        train['date'] = pd.to_datetime(train['date_time'], format='%Y-%m-%d').dt.date\n",
    "        test['date'] = pd.to_datetime(test['date_time'], format='%Y-%m-%d').dt.date\n",
    "        building_dates = [['2022-06-20', '2022-07-11', '2022-08-08', '2022-06-17'], ['2022-06-13', '2022-07-25', '2022-08-01'],\n",
    "                         ['2022-07-18', '2022-08-08'], ['2022-06-20', '2022-07-18', '2022-06-17', '2022-08-08'],\n",
    "                         ['2022-06-27', '2022-07-25', '2022-08-08'], ['2022-06-13', '2022-07-11', '2022-08-22']]\n",
    "\n",
    "        for index, b in enumerate([37,38,39,40,41,42]):\n",
    "            train.loc[train['building'] == b, 'holiday'] = 0\n",
    "            train.loc[(train['building'] == b) & (train['date'].isin([pd.to_datetime(i).date() for i in building_dates[index]])), 'holiday'] = 1\n",
    "            test.loc[test['building'] == b, 'holiday'] = 0\n",
    "            test.loc[(test['building'] == b) & (test['date'].isin([pd.to_datetime(i).date() for i in building_dates[index]])), 'holiday'] = 1\n",
    "    \n",
    "    return train, test\n",
    "    \n",
    "    \n",
    "    \n",
    "def process_info(data, is_train=True):\n",
    "    data.columns = ['building', 'type', 'all_area', 'cool_area', 'sun']\n",
    "    data['sun'] = data['sun'].replace('-', 0).astype('float')\n",
    "\n",
    "    value_dict = {value: index for index, value in enumerate(data['type'].unique())}\n",
    "    data['type'] = data['type'].map(value_dict)\n",
    "    \n",
    "    filtered_data = data[(data['type'] == 7) & (data['cool_area'] != 0)]\n",
    "    result = (filtered_data['all_area'].iloc[1:].sum() / filtered_data['cool_area'].iloc[1:].sum())\n",
    "    condition = (data['type'] == 7) & (data['cool_area'] == 0)\n",
    "    data.loc[condition, 'cool_area'] = (data.loc[condition, 'all_area'] / result).astype('int')\n",
    "    \n",
    "    filtered_data = data[(data['type'] == 9) & (data['cool_area'] > 500)]\n",
    "    result = (filtered_data['all_area'].sum() / filtered_data['cool_area'].sum())\n",
    "    condition = (data['type'] == 9) & (data['cool_area'] < 500)\n",
    "    data.loc[condition, 'cool_area'] = round(data.loc[condition, 'all_area'] / result, 1)\n",
    "    \n",
    "    return data\n",
    "    \n",
    "    \n",
    "def get_train_and_test_data(mode):\n",
    "    building_info = pd.read_csv(os.path.join(base_path,'building_info.csv')).drop(['ESS저장용량(kWh)', 'PCS용량(kW)'], axis=1)\n",
    "    building_info = process_info(building_info)\n",
    "\n",
    "    train_data = pd.read_csv(os.path.join(base_path,'train.csv')).drop(['일조(hr)', '일사(MJ/m2)'], axis=1)\n",
    "    train_data.columns = ['num_date_time', 'building', 'date_time', 'temp', 'prec', 'wind', 'hum', 'target']\n",
    "    train_data = process_data(train_data, mode)\n",
    "\n",
    "    test_data = pd.read_csv(os.path.join(base_path,'test.csv'))\n",
    "    test_data.columns = ['num_date_time', 'building', 'date_time', 'temp', 'prec', 'wind', 'hum']\n",
    "    test_data = process_data(test_data, mode)\n",
    "    \n",
    "    train_data, test_data = mean_std(train_data, test_data, mode)\n",
    "    \n",
    "    if mode == 'all' or mode == 'gu_all':\n",
    "        train_data = train_data.merge(building_info, on='building', how='left')\n",
    "        test_data = test_data.merge(building_info, on='building', how='left')\n",
    "        \n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T03:37:35.490986Z",
     "iopub.status.busy": "2023-09-01T03:37:35.490745Z",
     "iopub.status.idle": "2023-09-01T03:46:08.864791Z",
     "shell.execute_reply": "2023-09-01T03:46:08.863796Z",
     "shell.execute_reply.started": "2023-09-01T03:37:35.490966Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [03:01<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.404954637397799\n",
      "451.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [05:16<00:00,  3.17s/it]\n"
     ]
    }
   ],
   "source": [
    "gu_byb = ['num_date_time', 'building', 'date_time', 'temp', 'wind', 'hum',\n",
    "       'dow', 'month', 'week', 'dow_hour_mean', 'holiday',\n",
    "       'holiday_mean', 'holiday_std', 'hour_mean', 'hour_std', 'sin_time',\n",
    "       'cos_time', 'THI', 'WC', 'CDH', 'target']\n",
    "\n",
    "train, test = get_train_and_test_data('gu_byb')\n",
    "\n",
    "train = train[gu_byb]\n",
    "test = test[gu_byb[:-1]]\n",
    "\n",
    "scores = []  \n",
    "best_it = [] \n",
    "\n",
    "score = pd.DataFrame({'building':range(1,101)})\n",
    "for i in tqdm(range(100)):\n",
    "    y = train.loc[train.building == i+1, 'target']\n",
    "    x = train.loc[train.building == i+1, ].iloc[:, 3:].drop(['target'], axis=1)\n",
    "    y_train, y_valid, x_train, x_valid = temporal_train_test_split(y = y, X = x, test_size = 168)\n",
    "    \n",
    "    xgb = XGBRegressor(colsample_bytree=0.8, eta=0.01, max_depth=5,\n",
    "             min_child_weight=6,n_estimators=2000, subsample=0.9, early_stopping_rounds=50, eval_metric=SMAPE)\n",
    "    \n",
    "    xgb.set_params(**{'objective':weighted_mse(100)})\n",
    "    \n",
    "    xgb.fit(x_train, y_train, eval_set=[(x_train, y_train), \n",
    "                                            (x_valid, y_valid)], verbose=False)\n",
    "    \n",
    "    y_pred = xgb.predict(x_valid)  \n",
    "            \n",
    "    sm = SMAPE(y_valid, y_pred)\n",
    "    scores.append(sm)\n",
    "    best_it.append(xgb.best_iteration+1) \n",
    "\n",
    "score['score'] = scores\n",
    "print(sum(scores)/len(scores)) \n",
    "print(sum(best_it)/len(best_it))\n",
    "# 4.404954637397799\n",
    "# 451.67\n",
    "\n",
    "preds = np.array([]) \n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    pred_df = pd.DataFrame()   \n",
    "    \n",
    "    for seed in [0,1,2,3,4]: \n",
    "        y_train = train.loc[train.building == i+1, 'target']\n",
    "        x_train = train.loc[train.building == i+1, ].iloc[:, 3:].drop(['target'], axis=1)\n",
    "        x_test = test.loc[test.building == i+1, ].iloc[:,3:]\n",
    "        \n",
    "        xgb = XGBRegressor(colsample_bytree=0.8, eta=0.01, max_depth=5, seed=seed,\n",
    "                 min_child_weight=6,n_estimators=best_it[i], subsample=0.9)\n",
    "\n",
    "        xgb.fit(x_train, y_train)\n",
    "        y_pred = xgb.predict(x_test)\n",
    "        pred_df.loc[:,seed] = y_pred   \n",
    "        \n",
    "    pred = pred_df.mean(axis=1)        \n",
    "    preds = np.append(preds, pred)   \n",
    "\n",
    "submission = pd.read_csv(os.path.join(base_path,'sample_submission.csv'))\n",
    "submission['answer'] = preds\n",
    "submission.to_csv('./gu_byb.csv', index = False)\n",
    "\n",
    "del train, test, scores, best_it, submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T03:46:08.867514Z",
     "iopub.status.busy": "2023-09-01T03:46:08.867161Z",
     "iopub.status.idle": "2023-09-01T03:46:24.068528Z",
     "shell.execute_reply": "2023-09-01T03:46:24.067167Z",
     "shell.execute_reply.started": "2023-09-01T03:46:08.867492Z"
    }
   },
   "outputs": [],
   "source": [
    "train, test = get_train_and_test_data('gu_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T03:46:24.070129Z",
     "iopub.status.busy": "2023-09-01T03:46:24.069862Z",
     "iopub.status.idle": "2023-09-01T03:46:24.076334Z",
     "shell.execute_reply": "2023-09-01T03:46:24.074972Z",
     "shell.execute_reply.started": "2023-09-01T03:46:24.070106Z"
    }
   },
   "outputs": [],
   "source": [
    "# 10시간 정도 소요됩니다.\n",
    "\n",
    "# import optuna\n",
    "# import optuna.logging\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "# train['date'] = pd.to_datetime(train['date'])\n",
    "# train['building'] = train['building'].astype('category')\n",
    "# train['type'] = train['type'].astype('category')\n",
    "\n",
    "# x_train = train[train['date'] < '2022-08-18'].drop(['num_date_time', 'date_time', 'target', 'date'], axis=1)\n",
    "# x_valid = train[train['date'] >= '2022-08-18'].drop(['num_date_time', 'date_time', 'target', 'date'], axis=1)\n",
    "# y_train = train[train['date'] < '2022-08-18']['target']\n",
    "# y_valid = train[train['date'] >= '2022-08-18']['target']\n",
    "\n",
    "# dtrain = xgb.DMatrix(data=x_train, label=y_train, enable_categorical=True)\n",
    "# dvalid = xgb.DMatrix(data=x_valid, label=y_valid, enable_categorical=True)\n",
    "\n",
    "# def objective(trial):\n",
    "#     param = {\n",
    "#         'reg_lambda': trial.suggest_float('reg_lambda', 1e-3, 10.0),\n",
    "#         'gamma': trial.suggest_float('gamma', 1e-3, 10),\n",
    "#         'reg_alpha': trial.suggest_float('reg_alpha', 1e-3, 10.0),\n",
    "#         'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n",
    "#         'subsample': trial.suggest_categorical('subsample', [0.6, 0.7, 0.8, 1.0]),\n",
    "#         'max_depth': trial.suggest_categorical('max_depth', [3, 4, 5, 6]),\n",
    "#         'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n",
    "#         'eta' : 0.1\n",
    "#     }\n",
    "\n",
    "#     model = xgb.train(params=param, dtrain=dtrain, num_boost_round=1000,\n",
    "#                       evals=[(dvalid, 'valid')], early_stopping_rounds=50, verbose_eval=False)\n",
    "\n",
    "#     preds = model.predict(dvalid)\n",
    "#     smape = SMAPE(y_valid, preds)\n",
    "\n",
    "#     return smape\n",
    "\n",
    "# study = optuna.create_study(direction='minimize', study_name=None)\n",
    "# with tqdm(total=500) as pbar:  \n",
    "#     def callback(study, trial):\n",
    "#         pbar.update(1)  \n",
    "\n",
    "#     study.optimize(objective, n_trials=500, callbacks=[callback])\n",
    "    \n",
    "# df = study.trials_dataframe().sort_values(by=['value'], ascending=[True]).reset_index(drop=True)\n",
    "# df.to_csv('parameters.csv', index=False)\n",
    "# df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T03:46:24.078633Z",
     "iopub.status.busy": "2023-09-01T03:46:24.078279Z",
     "iopub.status.idle": "2023-09-01T03:46:24.094083Z",
     "shell.execute_reply": "2023-09-01T03:46:24.093080Z",
     "shell.execute_reply.started": "2023-09-01T03:46:24.078602Z"
    }
   },
   "outputs": [],
   "source": [
    "colsample_bytree = [0.9,0.9,0.8,0.9,0.9]\n",
    "gamma = [8.161415, 8.915918, 8.249356, 6.575258, 8.487247]\n",
    "max_depth = [6,5,6,6,6]\n",
    "min_child_weight = [47,8,30,54,77]\n",
    "reg_alpha = [6.721675, 6.736361, 7.109872, 7.016596, 6.186162]\n",
    "reg_lambda = [6.064121, 5.957454, 5.927528, 5.413840, 4.798086]\n",
    "subsample = [1.0,1.0,1.0,1.0,1.0]\n",
    "value = [5.010795, 5.016419, 5.017388, 5.023210, 5.028135]\n",
    "\n",
    "df = pd.DataFrame({'params_colsample_bytree':colsample_bytree, 'params_gamma':gamma, 'params_max_depth':max_depth, 'params_min_child_weight':min_child_weight,\n",
    "             'params_reg_alpha':reg_alpha, 'params_reg_lambda':reg_lambda, 'params_subsample':subsample, 'value':value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T03:46:24.095727Z",
     "iopub.status.busy": "2023-09-01T03:46:24.095426Z",
     "iopub.status.idle": "2023-09-01T03:46:57.397931Z",
     "shell.execute_reply": "2023-09-01T03:46:57.396514Z",
     "shell.execute_reply.started": "2023-09-01T03:46:24.095703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.010795060857856 251\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "gu_all = ['num_date_time', 'building', 'date_time', 'temp', 'wind', 'hum',\n",
    "       'type', 'all_area', 'cool_area', 'dow', 'month', 'week',\n",
    "       'dow_hour_mean', 'date', 'holiday', 'holiday_mean', 'holiday_std',\n",
    "       'hour_mean', 'hour_std', 'sin_time', 'cos_time', 'THI', 'WC', 'CDH', 'target']\n",
    "\n",
    "train, test = train[gu_all], test[gu_all[:-1]]\n",
    "\n",
    "train['date'] = pd.to_datetime(train['date'])\n",
    "train['building'] = train['building'].astype('category')\n",
    "train['type'] = train['type'].astype('category')\n",
    "\n",
    "x_train = train[train['date'] < f'2022-08-18'].drop(['num_date_time', 'date_time', 'target', 'date'], axis=1).reset_index(drop=True)\n",
    "x_valid = train[train['date'] >= f'2022-08-18'].drop(['num_date_time', 'date_time', 'target', 'date'], axis=1).reset_index(drop=True)\n",
    "y_train = train[train['date'] < f'2022-08-18']['target'].reset_index(drop=True)\n",
    "y_valid = train[train['date'] >= f'2022-08-18']['target'].reset_index(drop=True)\n",
    "\n",
    "dtrain = xgb.DMatrix(data=x_train, label=y_train, enable_categorical=True)\n",
    "dvalid = xgb.DMatrix(data=x_valid, label=y_valid, enable_categorical=True)\n",
    "\n",
    "\n",
    "param = {\n",
    "    'reg_lambda': df['params_reg_lambda'][0] ,\n",
    "    'gamma': df['params_gamma'][0],\n",
    "    'reg_alpha': df['params_reg_alpha'][0] ,\n",
    "    'colsample_bytree': df['params_colsample_bytree'][0] ,\n",
    "    'subsample': df['params_subsample'][0] ,\n",
    "    'max_depth': df['params_max_depth'][0],\n",
    "    'min_child_weight': df['params_min_child_weight'][0],\n",
    "}\n",
    "\n",
    "model = xgb.train(params=param, dtrain=dtrain, num_boost_round=1000,\n",
    "                  evals=[(dvalid, 'valid')], early_stopping_rounds=100, verbose_eval=False)\n",
    "\n",
    "preds = model.predict(dvalid)\n",
    "smape = SMAPE(y_valid, preds)\n",
    "\n",
    "best_it = model.best_iteration+1\n",
    "building_score = []\n",
    "for i in range(100):\n",
    "    building_score.append(SMAPE(y_valid[i*168:(i+1)*168], preds[i*168:(i+1)*168]))\n",
    "    \n",
    "score['score_all'] = building_score\n",
    "score.to_csv('./score.csv', index=False)\n",
    "print(smape, best_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T03:46:57.399448Z",
     "iopub.status.busy": "2023-09-01T03:46:57.399106Z",
     "iopub.status.idle": "2023-09-01T03:49:03.524307Z",
     "shell.execute_reply": "2023-09-01T03:49:03.523477Z",
     "shell.execute_reply.started": "2023-09-01T03:46:57.399423Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [02:05<00:00, 25.19s/it]\n"
     ]
    }
   ],
   "source": [
    "preds = np.array([])\n",
    "\n",
    "test = test.copy()\n",
    "test['date'] = pd.to_datetime(test['date'])\n",
    "test['building'] = test['building'].astype('category')\n",
    "test['type'] = test['type'].astype('category')\n",
    "\n",
    "x_train = train.drop(['num_date_time', 'date_time', 'target', 'date'], axis=1)\n",
    "x_test = test.drop(['num_date_time', 'date_time', 'date'], axis=1)\n",
    "y_train = train['target']\n",
    "\n",
    "dtrain = xgb.DMatrix(data=x_train, label=y_train, enable_categorical=True)\n",
    "dtest = xgb.DMatrix(data=x_test, enable_categorical=True)\n",
    "\n",
    "pred_df = pd.DataFrame()   \n",
    "\n",
    "for seed in tqdm(range(5)):\n",
    "    param = {\n",
    "        'reg_lambda': df['params_reg_lambda'][0] ,\n",
    "        'gamma': df['params_gamma'][0],\n",
    "        'reg_alpha': df['params_reg_alpha'][0] ,\n",
    "        'colsample_bytree': df['params_colsample_bytree'][0] ,\n",
    "        'subsample': df['params_subsample'][0] ,\n",
    "        'max_depth': df['params_max_depth'][0],\n",
    "        'min_child_weight': df['params_min_child_weight'][0],\n",
    "        'seed':seed,\n",
    "    }\n",
    "\n",
    "    model = xgb.train(params=param, dtrain=dtrain, num_boost_round=best_it)\n",
    "\n",
    "    y_pred = model.predict(dtest)\n",
    "    pred_df.loc[:,seed] = y_pred   \n",
    "\n",
    "pred = pred_df.mean(axis=1)        \n",
    "preds = np.append(preds, pred)   \n",
    "    \n",
    "submission = pd.read_csv(os.path.join(base_path,'sample_submission.csv'))\n",
    "submission['answer'] = preds\n",
    "submission.to_csv('./gu_all.csv', index = False)\n",
    "\n",
    "del train, test, df, submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T03:49:03.526125Z",
     "iopub.status.busy": "2023-09-01T03:49:03.525616Z",
     "iopub.status.idle": "2023-09-01T03:49:48.432375Z",
     "shell.execute_reply": "2023-09-01T03:49:48.431440Z",
     "shell.execute_reply.started": "2023-09-01T03:49:03.526096Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:26<00:00,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.17304185151095\n",
      "107.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "byb = ['num_date_time', 'building', 'date_time', 'temp', 'wind', 'hum',\n",
    "       'dow', 'month', 'week', 'dow_hour_mean', 'holiday',\n",
    "       'holiday_mean', 'holiday_std', 'hour_mean', 'hour_std', 'sin_time',\n",
    "       'cos_time', 'THI', 'WC', 'CDH', 'summer_cos', 'summer_sin', 'target']\n",
    "\n",
    "train, test = get_train_and_test_data('byb')\n",
    "train, test = train[byb], test[byb[:-1]]\n",
    "\n",
    "scores = []   \n",
    "best_it = []  \n",
    "\n",
    "for b in tqdm(range(100)):\n",
    "    y = train.loc[train.building == b+1, 'target']\n",
    "    x = train.loc[train.building == b+1, ].iloc[:, 3:].drop(['target'], axis=1)\n",
    "    y_train, y_valid, x_train, x_valid = temporal_train_test_split(y = y, X = x, test_size = 168)\n",
    "    \n",
    "    xgb = XGBRegressor(colsample_bytree=0.8, eta=0.1, max_depth=5,\n",
    "         min_child_weight=6,n_estimators=1000, subsample=0.9, early_stopping_rounds=50)\n",
    "    \n",
    "    xgb.fit(x_train, y_train, eval_set=[(x_valid, y_valid)], verbose=False)\n",
    "    \n",
    "    y_pred = xgb.predict(x_valid)  \n",
    "\n",
    "            \n",
    "    sm = SMAPE(y_valid, y_pred)\n",
    "    scores.append(sm)\n",
    "    best_it.append(xgb.best_iteration+1) \n",
    "    \n",
    "print(sum(scores)/len(scores)) \n",
    "print(sum(best_it)/len(best_it))\n",
    "# 5.17304185151095\n",
    "# 107.93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T03:49:48.435684Z",
     "iopub.status.busy": "2023-09-01T03:49:48.435399Z",
     "iopub.status.idle": "2023-09-01T03:52:58.734904Z",
     "shell.execute_reply": "2023-09-01T03:52:58.733287Z",
     "shell.execute_reply.started": "2023-09-01T03:49:48.435662Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [03:10<00:00,  1.90s/it]\n"
     ]
    }
   ],
   "source": [
    "preds = np.array([]) \n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    pred_df = pd.DataFrame()   \n",
    "    \n",
    "    for seed in [0,1,2,3,4,5,6,7,8,9,10]: \n",
    "        y_train = train.loc[train.building == i+1, 'target']\n",
    "        x_train = train.loc[train.building == i+1, ].iloc[:, 3:].drop(['target'], axis=1)\n",
    "        x_test = test.loc[test.building == i+1, ].iloc[:,3:]\n",
    "        \n",
    "        xgb = XGBRegressor(colsample_bytree=0.8, eta=0.1, max_depth=5, seed=seed,\n",
    "             min_child_weight=6,n_estimators=best_it[i], subsample=0.9)\n",
    "        \n",
    "        xgb.fit(x_train, y_train)\n",
    "        y_pred = xgb.predict(x_test)\n",
    "        pred_df.loc[:,seed] = y_pred   \n",
    "        \n",
    "    pred = pred_df.mean(axis=1)        \n",
    "    preds = np.append(preds, pred)   \n",
    "    \n",
    "submission = pd.read_csv(os.path.join(base_path,'sample_submission.csv'))\n",
    "submission['answer'] = preds\n",
    "submission.to_csv('./byb.csv', index = False)\n",
    "submission\n",
    "\n",
    "del train, test, scores, best_it, submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T03:52:58.736916Z",
     "iopub.status.busy": "2023-09-01T03:52:58.736570Z",
     "iopub.status.idle": "2023-09-01T03:52:58.743105Z",
     "shell.execute_reply": "2023-09-01T03:52:58.741776Z",
     "shell.execute_reply.started": "2023-09-01T03:52:58.736890Z"
    }
   },
   "outputs": [],
   "source": [
    "# 10시간 정도 소요됩니다.\n",
    "\n",
    "# import optuna\n",
    "# import optuna.logging\n",
    "\n",
    "# optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "# train['date'] = pd.to_datetime(train['date'])\n",
    "# train['building'] = train['building'].astype('category')\n",
    "# train['type'] = train['type'].astype('category')\n",
    "\n",
    "# x_train = train[train['date'] < '2022-08-18'].drop(['num_date_time', 'date_time', 'target', 'date'], axis=1)\n",
    "# x_valid = train[train['date'] >= '2022-08-18'].drop(['num_date_time', 'date_time', 'target', 'date'], axis=1)\n",
    "# y_train = train[train['date'] < '2022-08-18']['target']\n",
    "# y_valid = train[train['date'] >= '2022-08-18']['target']\n",
    "\n",
    "# dtrain = xgb.DMatrix(data=x_train, label=y_train, enable_categorical=True)\n",
    "# dvalid = xgb.DMatrix(data=x_valid, label=y_valid, enable_categorical=True)\n",
    "\n",
    "# def objective(trial):\n",
    "#     param = {\n",
    "#         'reg_lambda': trial.suggest_float('reg_lambda', 1e-3, 10.0),\n",
    "#         'gamma': trial.suggest_float('gamma', 1e-3, 10),\n",
    "#         'reg_alpha': trial.suggest_float('reg_alpha', 1e-3, 10.0),\n",
    "#         'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n",
    "#         'subsample': trial.suggest_categorical('subsample', [0.6, 0.7, 0.8, 1.0]),\n",
    "#         'max_depth': trial.suggest_categorical('max_depth', [3, 4, 5, 6]),\n",
    "#         'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n",
    "#         'eta' : 0.1\n",
    "#     }\n",
    "\n",
    "#     model = xgb.train(params=param, dtrain=dtrain, num_boost_round=1000,\n",
    "#                       evals=[(dvalid, 'valid')], early_stopping_rounds=50, verbose_eval=False)\n",
    "\n",
    "#     preds = model.predict(dvalid)\n",
    "#     smape = SMAPE(y_valid, preds)\n",
    "\n",
    "#     return smape\n",
    "\n",
    "# study = optuna.create_study(direction='minimize', study_name=None)\n",
    "# with tqdm(total=500) as pbar:  \n",
    "#     def callback(study, trial):\n",
    "#         pbar.update(1)  \n",
    "\n",
    "#     study.optimize(objective, n_trials=500, callbacks=[callback])\n",
    "    \n",
    "# df = study.trials_dataframe().sort_values(by=['value'], ascending=[True]).reset_index(drop=True)\n",
    "# df.to_csv('parameters2.csv', index=False)\n",
    "# df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T03:52:58.744657Z",
     "iopub.status.busy": "2023-09-01T03:52:58.744341Z",
     "iopub.status.idle": "2023-09-01T03:52:58.767006Z",
     "shell.execute_reply": "2023-09-01T03:52:58.765637Z",
     "shell.execute_reply.started": "2023-09-01T03:52:58.744628Z"
    }
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    [61, 61, 4.946742, '2023-08-18 11:59:30.066695', '2023-08-18 12:01:19.655572', '0 days 00:01:49.588877', 0.7, 0.695975, 6, 43, 6.357773, 2.568356, 1.0, 'COMPLETE'],\n",
    "    [23, 23, 4.950789, '2023-08-18 11:24:36.282096', '2023-08-18 11:25:56.779154', '0 days 00:01:20.497058', 0.7, 0.023800, 6, 30, 6.278440, 1.460707, 1.0, 'COMPLETE'],\n",
    "    [14, 14, 4.975757, '2023-08-18 11:16:59.783126', '2023-08-18 11:18:02.962945', '0 days 00:01:03.179819', 0.7, 0.966742, 6, 36, 3.762862, 0.362957, 1.0, 'COMPLETE'],\n",
    "    [51, 51, 4.986851, '2023-08-18 11:51:40.355474', '2023-08-18 11:52:48.657127', '0 days 00:01:08.301653', 0.7, 1.034617, 6, 49, 5.606792, 1.690612, 1.0, 'COMPLETE'],\n",
    "    [31, 31, 4.994619, '2023-08-18 11:32:34.984062', '2023-08-18 11:33:29.901314', '0 days 00:00:54.917252', 0.7, 0.094354, 6, 36, 5.006265, 1.527805, 1.0, 'COMPLETE'],\n",
    "    [71, 71, 5.450572, '2023-08-14 13:17:40.337706', '2023-08-14 13:20:33.336589', '0 days 00:02:52.998883', 1.0, 4.632731, 6, 18, 2.979220, 7.641126, 0.7, 'COMPLETE'],\n",
    "    [11, 11, 5.451309, '2023-08-14 11:00:11.878935', '2023-08-14 11:02:55.559494', '0 days 00:02:43.680559', 0.9, 8.375491, 6, 1, 4.829945, 7.857255, 0.7, 'COMPLETE'],\n",
    "    [32, 32, 5.451501, '2023-08-14 11:48:49.899305', '2023-08-14 11:51:31.199312', '0 days 00:02:41.300007', 0.9, 4.436363, 6, 1, 3.906413, 6.982815, 0.7, 'COMPLETE'],\n",
    "    [21, 21, 5.451785, '2023-08-14 11:22:30.440656', '2023-08-14 11:25:13.331292', '0 days 00:02:42.890636', 0.9, 3.917213, 6, 3, 4.037673, 8.432115, 0.7, 'COMPLETE'],\n",
    "    [89, 89, 5.451788, '2023-08-14 14:07:31.956578', '2023-08-14 14:10:27.640167', '0 days 00:02:55.683589', 1.0, 4.768440, 6, 9, 3.470846, 8.564962, 0.7, 'COMPLETE']\n",
    "]\n",
    "\n",
    "columns = ['number', 'number', 'value', 'datetime_start', 'datetime_complete', 'duration', 'params_colsample_bytree', 'params_gamma', 'params_max_depth', 'params_min_child_weight', 'params_reg_alpha', 'params_reg_lambda', 'params_subsample', 'state']\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "df['datetime_start'] = pd.to_datetime(df['datetime_start'])\n",
    "df['datetime_complete'] = pd.to_datetime(df['datetime_complete'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T04:04:34.593753Z",
     "iopub.status.busy": "2023-09-01T04:04:34.593412Z",
     "iopub.status.idle": "2023-09-01T04:04:34.607894Z",
     "shell.execute_reply": "2023-09-01T04:04:34.606698Z",
     "shell.execute_reply.started": "2023-09-01T04:04:34.593730Z"
    }
   },
   "outputs": [],
   "source": [
    "def ratio_2(ratio):\n",
    "    score = pd.read_csv('./score.csv')\n",
    "    gu_byb = pd.read_csv('./gu_byb.csv')\n",
    "    \n",
    "    ratio = np.array(ratio)\n",
    "\n",
    "    category_mappings = {\n",
    "        'one': ([32, 33, 34, 35, 36], [0.997, 0.999, 0.996, 0.997, 0.995, 0.994, 0.996], [], True),\n",
    "        'one_': ([56, 58], [0.997, 0.999, 0.998, 0.999, 0.995, 0.994, 0.996], [], True),\n",
    "        'two': ([24, 25, 26, 27, 48, 49, 50], [0.987, 0.987, 0.985, 0.987, 0.984, 0.982, 0.985], [], True),\n",
    "        'two_': ([23, 55], [0.987, 0.987, 0.995, 0.998, 0.984, 0.982, 0.985], [], True),\n",
    "        'depart': ([37, 38, 39, 40, 41, 42, 43, 44, 85], [0.998]*7, [], False),\n",
    "        'mart': ([86, 87, 88, 89, 90, 91, 92], [0.998]*7, [4], False),\n",
    "        'aprt': ([64, 65, 66, 67, 68, 61, 62, 63], [0.985, 0.985, 0.985, 0.987, 0.98, 0.98, 0.987], [], True),\n",
    "        'mon': ([2, 3, 54], [0.998]*7, [4], False),\n",
    "        '5': ([5], [0.998]*7, [0,4,5,6], False),\n",
    "        '8': ([8], [0.998]*7, [3], False)\n",
    "    }\n",
    "\n",
    "    for i in range(100):\n",
    "        rest =  True\n",
    "        for category, (ids, ratios, d, a_a) in category_mappings.items():\n",
    "            if i + 1 in ids:\n",
    "                rest = False\n",
    "                for j in range(7):\n",
    "                    if j in d:\n",
    "                        continue\n",
    "                    ran,ge = 168*i+24*j,168*i+24*(j+1)\n",
    "                    if a_a:\n",
    "                        if category == 'aprt':\n",
    "                            ratio[ran:ge] *= ratios[j]\n",
    "                        else:\n",
    "                            ratio[ran:ge] = gu_byb.answer[ran:ge]*ratios[j]\n",
    "                    else:\n",
    "                        ratio[ran+9:ge-3] *= ratios[j]\n",
    "                break\n",
    "        if rest:\n",
    "            for j in range(7):\n",
    "                ran,ge = 168*i+24*j,168*i+24*(j+1)\n",
    "                if j in [2, 3]:\n",
    "                    continue\n",
    "                ratio[ran+9:ge-3] *= ratios[j]\n",
    "\n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T03:52:58.782124Z",
     "iopub.status.busy": "2023-09-01T03:52:58.781844Z",
     "iopub.status.idle": "2023-09-01T03:54:41.848475Z",
     "shell.execute_reply": "2023-09-01T03:54:41.847837Z",
     "shell.execute_reply.started": "2023-09-01T03:52:58.782102Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.946742493265771 844\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "_all = ['num_date_time', 'building', 'date_time', 'temp', 'prec', 'wind', 'hum',\n",
    "       'type', 'all_area', 'cool_area', 'sun', 'dow', 'month',\n",
    "       'week', 'avg_temp', 'max_temp', 'min_temp', 'temp_diff',\n",
    "       'dow_hour_mean', 'holiday', 'holiday_mean', 'holiday_std',\n",
    "       'hour_mean', 'hour_std', 'sin_time', 'cos_time', 'THI', 'WC', 'CDH', 'target']\n",
    "\n",
    "train, test = get_train_and_test_data('all')\n",
    "train, test = train[_all], test[_all[:-1]]\n",
    "\n",
    "train['date'] = pd.to_datetime(train['date_time'])\n",
    "train['building'] = train['building'].astype('category')\n",
    "train['type'] = train['type'].astype('category')\n",
    "\n",
    "x_train = train[train['date'] < '2022-08-18'].drop(['num_date_time', 'date_time', 'target', 'date'], axis=1)\n",
    "x_valid = train[train['date'] >= '2022-08-18'].drop(['num_date_time', 'date_time', 'target', 'date'], axis=1)\n",
    "y_train = train[train['date'] < '2022-08-18']['target']\n",
    "y_valid = train[train['date'] >= '2022-08-18']['target']\n",
    "\n",
    "dtrain = xgb.DMatrix(data=x_train, label=y_train, enable_categorical=True)\n",
    "dvalid = xgb.DMatrix(data=x_valid, label=y_valid, enable_categorical=True)\n",
    "\n",
    "param = {\n",
    "    'reg_lambda': df['params_reg_lambda'][0] ,\n",
    "    'gamma': df['params_gamma'][0],\n",
    "    'reg_alpha': df['params_reg_alpha'][0] ,\n",
    "    'colsample_bytree': df['params_colsample_bytree'][0] ,\n",
    "    'subsample': df['params_subsample'][0] ,\n",
    "    'max_depth': df['params_max_depth'][0],\n",
    "    'min_child_weight': df['params_min_child_weight'][0],\n",
    "    'eta' : 0.1,\n",
    "}\n",
    "\n",
    "\n",
    "model = xgb.train(params=param, dtrain=dtrain, num_boost_round=1000,\n",
    "                  evals=[(dvalid, 'valid')], early_stopping_rounds=50, verbose_eval=False)\n",
    "\n",
    "preds = model.predict(dvalid)\n",
    "\n",
    "smape = SMAPE(y_valid, preds)\n",
    "\n",
    "score = smape\n",
    "best_it = model.best_iteration+1\n",
    "print(score, best_it) # 4.946742493265771 [844]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T03:54:41.850685Z",
     "iopub.status.busy": "2023-09-01T03:54:41.850330Z",
     "iopub.status.idle": "2023-09-01T04:01:22.615043Z",
     "shell.execute_reply": "2023-09-01T04:01:22.614053Z",
     "shell.execute_reply.started": "2023-09-01T03:54:41.850659Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:40<00:00, 80.12s/it]\n"
     ]
    }
   ],
   "source": [
    "preds = np.array([])\n",
    "\n",
    "test['date'] = pd.to_datetime(test['date_time'])\n",
    "test['building'] = test['building'].astype('category')\n",
    "test['type'] = test['type'].astype('category')\n",
    "\n",
    "x_train = train.drop(['num_date_time', 'date_time', 'target', 'date'], axis=1)\n",
    "x_test = test.drop(['num_date_time', 'date_time', 'date'], axis=1)\n",
    "y_train = train['target']\n",
    "\n",
    "dtrain = xgb.DMatrix(data=x_train, label=y_train, enable_categorical=True)\n",
    "dtest = xgb.DMatrix(data=x_test, enable_categorical=True)\n",
    "\n",
    "pred_df = pd.DataFrame()\n",
    "\n",
    "i = 0\n",
    "for seed in tqdm(range(5)):\n",
    "    param = {\n",
    "        'reg_lambda': df['params_reg_lambda'][0] ,\n",
    "        'gamma': df['params_gamma'][0],\n",
    "        'reg_alpha': df['params_reg_alpha'][0] ,\n",
    "        'colsample_bytree': df['params_colsample_bytree'][0] ,\n",
    "        'subsample': df['params_subsample'][0] ,\n",
    "        'max_depth': df['params_max_depth'][0],\n",
    "        'min_child_weight': df['params_min_child_weight'][0],\n",
    "        'seed':seed,\n",
    "        'eta':0.1\n",
    "    }\n",
    "\n",
    "    model = xgb.train(params=param, dtrain=dtrain, num_boost_round=best_it-100)\n",
    "\n",
    "    y_pred = model.predict(dtest)\n",
    "    pred_df.loc[:,seed] = y_pred   \n",
    "\n",
    "pred = pred_df.mean(axis=1)      \n",
    "preds = np.append(preds, pred)   \n",
    "    \n",
    "submission = pd.read_csv(os.path.join(base_path,'sample_submission.csv'))\n",
    "submission['answer'] = preds\n",
    "submission.to_csv('./all.csv', index = False)\n",
    "\n",
    "del train, test\n",
    "del dtrain, dtest, x_train, x_test, y_train, pred, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T04:04:41.070143Z",
     "iopub.status.busy": "2023-09-01T04:04:41.069067Z",
     "iopub.status.idle": "2023-09-01T04:04:41.426662Z",
     "shell.execute_reply": "2023-09-01T04:04:41.425705Z",
     "shell.execute_reply.started": "2023-09-01T04:04:41.070108Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_date_time</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_20220825 00</td>\n",
       "      <td>1802.679429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_20220825 01</td>\n",
       "      <td>1753.577321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_20220825 02</td>\n",
       "      <td>1636.800049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_20220825 03</td>\n",
       "      <td>1567.376650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_20220825 04</td>\n",
       "      <td>1611.254585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16795</th>\n",
       "      <td>100_20220831 19</td>\n",
       "      <td>857.328171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16796</th>\n",
       "      <td>100_20220831 20</td>\n",
       "      <td>799.987912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16797</th>\n",
       "      <td>100_20220831 21</td>\n",
       "      <td>718.364396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16798</th>\n",
       "      <td>100_20220831 22</td>\n",
       "      <td>617.148597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16799</th>\n",
       "      <td>100_20220831 23</td>\n",
       "      <td>526.372424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         num_date_time       answer\n",
       "0        1_20220825 00  1802.679429\n",
       "1        1_20220825 01  1753.577321\n",
       "2        1_20220825 02  1636.800049\n",
       "3        1_20220825 03  1567.376650\n",
       "4        1_20220825 04  1611.254585\n",
       "...                ...          ...\n",
       "16795  100_20220831 19   857.328171\n",
       "16796  100_20220831 20   799.987912\n",
       "16797  100_20220831 21   718.364396\n",
       "16798  100_20220831 22   617.148597\n",
       "16799  100_20220831 23   526.372424\n",
       "\n",
       "[16800 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(os.path.join(base_path, 'test.csv'))\n",
    "test.columns = ['num_date_time', 'building', 'date_time', 'temp', 'prec', 'wind', 'hum']\n",
    "date = pd.to_datetime(test.date_time)\n",
    "test['dow'] = date.dt.weekday\n",
    "test['hour'] = date.dt.hour\n",
    "\n",
    "score = pd.read_csv('./score.csv')\n",
    "gu_byb = pd.read_csv('./gu_byb.csv')\n",
    "gu_all = pd.read_csv('./gu_all.csv')\n",
    "byb = pd.read_csv('./byb.csv')\n",
    "xg_all = pd.read_csv('./all.csv')\n",
    "\n",
    "ratio = []\n",
    "for i in range(100):\n",
    "    s1, s2 = score.score[i], score.score_all[i]\n",
    "    b1 = gu_all.answer[i * 168 : (i + 1) * 168] * (s1 / (s1 + s2))\n",
    "    b2 = gu_byb.answer[i * 168 : (i + 1) * 168] * (s2 / (s1 + s2)) * 0.965\n",
    "    building = [i + j for i, j in zip(b1, b2)]\n",
    "    ratio += building\n",
    "\n",
    "test['ratio'] = ((gu_all.answer + gu_byb.answer) * 0.5 * 0.98 + ratio) * 0.5\n",
    "test['gu_all'] = gu_all.answer\n",
    "\n",
    "ratio_values = [0.98, 0.975, 0.975, 0.99, 0.99, 0.985, 0.985]\n",
    "test['target'] = test['ratio'] * 0.5 + gu_all['answer'] * 0.5\n",
    "test['target'] = test.apply(lambda row: row['target'] * ratio_values[row['dow']], axis=1)\n",
    "\n",
    "ratio = ratio_2(np.array(test.target * 0.5 + (byb.answer * 0.5 + xg_all.answer * 0.5) * 0.5))\n",
    "\n",
    "submission = pd.read_csv(os.path.join(base_path, 'sample_submission.csv'))\n",
    "submission['answer'] = ratio\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
