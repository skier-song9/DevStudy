The dataset includes ARI, year, month, day, hour, U_WIND, V_WIND, BN.
Objective of the analysis is to predict U_WIND, V_WIND, BN by ARI, year, month, day, hour. So that input data will be ARI, year, month, day, hour.
ARI refers to the location data. 

Assume that ARI data has already been labelencoded and others are float value.

I want to predict  U_WIND, V_WIND, BN according to ARI and time data(year, month, day, hour). 

Make me an LSTM model. 
model should include at leasr three layers.
Activation function of output layer is identity function or linear function.
the dimension of Output data must be torch.Size([1,input_data.size(1),3])
And follow bellowing settings.
Use early_stopping method of which patience value is 30.
Batch_size is 150.
Use GPU device which is named 'cuda:0'.
Split the data in the ratio of 6:2:2 by the name tr:val:test.
Be careful not to make an error when computate the mse


==================================================================

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error

# Split data
X_train, X_val_test, y_train, y_val_test = train_test_split(x_wind_bn_train, y_wind_bn_train, test_size=0.4, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=42)

# Scale features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)
X_test_scaled = scaler.transform(X_test)

# Convert to tensors
X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32).unsqueeze(1)
y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)
X_val_tensor = torch.tensor(X_val_scaled, dtype=torch.float32).unsqueeze(1)
y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).unsqueeze(1)
X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32).unsqueeze(1)
y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1)

# Define LSTM model
class LSTM(nn.Module):
    def __init__(self, input_size, hidden_size, output_size, num_layers):
        super(LSTM, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)
        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)
        out, _ = self.lstm(x, (h0, c0))
        out = self.fc(out[:, -1, :])
        return out

# Initialize variables
input_size = X_train.shape[1]
hidden_size = 128
output_size = y_train.shape[1]
num_layers = 3
batch_size = 150
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

# Create dataloaders
train_dataset = TensorDataset(X_train_tensor, y_train_tensor)
val_dataset = TensorDataset(X_val_tensor, y_val_tensor)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

# Create model
model = LSTM(input_size, hidden_size, output_size, num_layers).to(device)

# Define loss function and optimizer
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Train the model
patience = 30
best_loss = float('inf')
no_improvement = 0
for epoch in range(1, 1001):
    model.train()
    train_loss = 0

    for inputs, targets in train_dataloader:
        inputs = inputs.to(device)
        targets = targets.to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, targets)
        train_loss += loss.item() * inputs.size(0)
        loss.backward()
        optimizer.step()

    average_train_loss = train_loss / len(train_dataloader.dataset)

    model.eval()
    val_loss = 0
    with torch.no_grad():
        for inputs, targets in val_dataloader:
            inputs = inputs.to(device)
            targets = targets.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            val_loss += loss.item() * inputs.size(0)

        average_val_loss = val_loss / len(val_dataloader.dataset)

        if average_val_loss < best_loss:
            best_loss = average_val_loss
            no_improvement = 0
        else:
            no_improvement += 1

        if no_improvement >= patience:
            print("Early stopping. No improvement in validation loss.")
            break

# Test the model
X_test_tensor = X_test_tensor.to(device)
y_test_tensor = y_test_tensor.to(device)
model.eval()
test_loss = 0
with torch.no_grad():
    outputs = model(X_test_tensor)
    test_loss = criterion(outputs, y_test_tensor)

test_loss.item()


==================================================================



# Train the model
best_loss = float('inf')
early_stopping_counter = 0
for epoch in range(1000):
  wind_model.train()
  for batch_x, batch_y in train_loader:
    optimizer.zero_grad()
    output = wind_model(batch_x)
    loss = criterion(output, batch_y)
    loss.backward()
    optimizer.step()
  
  wind_model.eval()
  with torch.no_grad():
    val_loss = criterion(wind_model(x_val_tensor), y_val_tensor)
    if val_loss < best_loss:
      best_loss = val_loss
      torch.save(wind_model.state_dict(), 'best_model.pth')
      early_stopping_counter = 0
    else:
      early_stopping_counter += 1
      if early_stopping_counter >= patience:
        break

In the above code, the bellow error has ocurred.
"C:\Users\songkyu\anaconda3\envs\Python39_DA\lib\site-packages\torch\nn\modules\loss.py:535: UserWarning: Using a target size (torch.Size([1, 45650, 3])) that is different to the input size (torch.Size([1, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)"

What is the problems?




if gpu_devices:
    device = tf.device(gpu_devices[0])
    print("Assigned GPU:", device)