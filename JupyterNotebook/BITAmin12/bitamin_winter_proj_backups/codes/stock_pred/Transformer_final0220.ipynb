{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc80feb9",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2059c61b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T20:00:48.531450Z",
     "start_time": "2024-02-21T20:00:31.621089Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "2059c61b",
    "outputId": "576afb16-4157-4337-f4db-d04264361874"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: not using Google CoLab\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import category_encoders as ce\n",
    "# import copy\n",
    "# import polars as pl\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib import font_manager, rc\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "# import plotly.express as px\n",
    "# %matplotlib inline\n",
    "# matplotlib.rcParams['font.family'] = 'Malgun Gothic' # 한글 패치\n",
    "# Preprocessing & Feature Engineering\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Hyperparameter Optimization\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Modeling\n",
    "# from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.ensemble import ExtraTreesClassifier\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier, XGBRegressor, XGBRFRegressor\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier, VotingRegressor\n",
    "from sklearn.ensemble import StackingClassifier, StackingRegressor\n",
    "# from sklearn.base import ClassifierMixin\n",
    "\n",
    "# CatBoost\n",
    "# from catboost import CatBoostRegressor\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Parameter\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import log_loss,mean_squared_error\n",
    "import sklearn\n",
    "\n",
    "# Utility\n",
    "import os\n",
    "import time\n",
    "import datetime # ⚠️2019년 12월30일과 31일의 week of year가 1인 오류가 있음\n",
    "import random\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "from IPython.display import Image\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import platform\n",
    "from itertools import combinations,product\n",
    "from scipy.stats.mstats import gmean\n",
    "import holidays\n",
    "\n",
    "# from bayes_opt import BayesianOptimization\n",
    "# from num2words import num2words\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.outliers_influence import OLSInfluence\n",
    "\n",
    "pd.set_option('display.max_row',None)\n",
    "pd.set_option('display.max_column',None)\n",
    "\n",
    "### Setting universal random_state\n",
    "np.random.seed(142)\n",
    "random.seed(142)\n",
    "sklearn.utils.check_random_state(142)\n",
    "torch.manual_seed(142)\n",
    "torch.backends.cudnn.deterministic=True\n",
    "torch.backends.cudnn.benchmark=False\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False\n",
    "\n",
    "# Make use of a GPU or MPS (Apple) if one is available.  (see module 3.2)\n",
    "has_mps = torch.backends.mps.is_built()\n",
    "device = \"mps\" if has_mps else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zVBHDA4xub-S",
   "metadata": {
    "id": "zVBHDA4xub-S"
   },
   "source": [
    "### Merge dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "jPRldaW5c653",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T20:00:48.562673Z",
     "start_time": "2024-02-21T20:00:48.534525Z"
    },
    "id": "jPRldaW5c653"
   },
   "outputs": [],
   "source": [
    "class PrepareData():\n",
    "    def __init__(self,stock_fp,news_fp):\n",
    "        self.stock_filepath = stock_fp\n",
    "        self.news_filepath = news_fp\n",
    "        self.topic_classes = ['CEO', 'CFO', 'Layoffs', 'Political', 'PressRelease', 'Undefined',\n",
    "       'cramer', 'earnings', 'gold', 'manda', 'paylimitwall', 'paywall',\n",
    "       'product', 'recession', 'tanalysis'] # undefined의 class가 5\n",
    "\n",
    "    def load_data(self):\n",
    "        stock = pd.read_csv(self.stock_filepath,index_col=0)\n",
    "        news = pd.read_csv(self.news_filepath,index_col=0)\n",
    "        ### parse date manually\n",
    "        stock['Date'] = pd.to_datetime(stock['Date'])\n",
    "        news['date'] = pd.to_datetime(news['date'])\n",
    "        return stock, news\n",
    "\n",
    "    def merging(self, stock, news):\n",
    "        ### fill na value of PINS column\n",
    "#         stock['PINS'] = stock['PINS'].fillna(stock['PINS'].iloc[75])\n",
    "\n",
    "        ### drop 'news_id' column\n",
    "#         news = news.drop(columns=['news_id'])\n",
    "\n",
    "        ### add date range from 18.01.02 to 18.12.31\n",
    "        temp_range = pd.DataFrame(dict(zip(stock.columns,[pd.date_range(start='2018-01-02',end='2018-12-31'),\n",
    "                                0,0,0,0, # 4\n",
    "                                0,0,0,0,\n",
    "                                0,0,0,0,\n",
    "                                0,0,0,0, # 16\n",
    "                                0,0,0,0,\n",
    "                                0,0,0,0,\n",
    "                                0,0,0,0, # 28\n",
    "                                0,0,0,0,\n",
    "                                0,0,0,0, # 36\n",
    "                                0 # 37\n",
    "                            ])))\n",
    "        stock_inc = pd.concat([temp_range,stock],axis=0)\n",
    "\n",
    "        ### merge stock_inc and news\n",
    "        # left = stock_inc\n",
    "        # on = date\n",
    "        # how = left\n",
    "        # rename 'date' to 'Date' of news df\n",
    "        news = news.rename(columns={'date':'Date'})\n",
    "        merged = pd.merge(left=stock_inc,right=news,on='Date',how='left')\n",
    "\n",
    "        ### Cut before 2018-02-13\n",
    "        merged = merged[42:].reset_index(drop=True)\n",
    "\n",
    "        # fill na with latest non-null values\n",
    "        columns_to_fill = ['source_name', 'topics', 'rank_score',\n",
    "                        'sentiment_Negative','sentiment_Neutral',\n",
    "                        'sentiment_Positive', 'type_Article', 'type_Video']\n",
    "        merged_fillna = merged.copy()\n",
    "        for column in columns_to_fill:\n",
    "            merged_fillna[column].fillna(method='ffill',inplace=True)\n",
    "\n",
    "        ### add moving average to sentiments\n",
    "        ma_nums = [5,60,120]\n",
    "        def mode_window(window):\n",
    "            return window.mode().iloc[0] if not len(window.mode())==0 else None\n",
    "        for num in ma_nums:\n",
    "            merged_fillna[f'{num}MA_sent_Neg']=merged_fillna['sentiment_Negative'].rolling(\n",
    "            window=num).mean()\n",
    "            merged_fillna[f'{num}MA_sent_Neu']=merged_fillna['sentiment_Neutral'].rolling(\n",
    "            window=num).mean()\n",
    "            merged_fillna[f'{num}MA_sent_Pos']=merged_fillna['sentiment_Positive'].rolling(\n",
    "            window=num).mean()\n",
    "        ### add moving mode to sentiments\n",
    "        for num in ma_nums:\n",
    "            merged_fillna[f'{num}MM_sent_Neg']=merged_fillna['sentiment_Negative'].rolling(\n",
    "            window=num).apply(mode_window)\n",
    "            merged_fillna[f'{num}MM_sent_Neu']=merged_fillna['sentiment_Neutral'].rolling(\n",
    "            window=num).apply(mode_window)\n",
    "            merged_fillna[f'{num}MM_sent_Pos']=merged_fillna['sentiment_Positive'].rolling(\n",
    "            window=num).apply(mode_window)\n",
    "        ### adding moving mode to topics\n",
    "        for num in ma_nums:\n",
    "            merged_fillna[f'{num}MM_topics']=merged_fillna['topics'].rolling(\n",
    "            window=num).apply(mode_window)\n",
    "\n",
    "        ### drop before 2019-01-02\n",
    "        total_df = merged_fillna.iloc[322:]\n",
    "        total_df = total_df.reset_index(drop=True)\n",
    "\n",
    "        ### drop unnecessaray columns\n",
    "        drop_cols = ['source_name','topics','rank_score',\n",
    "                    'sentiment_Negative','sentiment_Neutral',\n",
    "                    'sentiment_Positive','type_Article','type_Video']\n",
    "        total_df = total_df.drop(columns=drop_cols)\n",
    "\n",
    "        return total_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cXT6Ts-1dPIr",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T20:00:50.808598Z",
     "start_time": "2024-02-21T20:00:48.564785Z"
    },
    "id": "cXT6Ts-1dPIr"
   },
   "outputs": [],
   "source": [
    "stock_filepath = '../../data/stock_price/netflix_60.csv' # 각자 파일 경로 설정\n",
    "news_filepath = '../../data/scraping/news_processed_filtered_2.csv'\n",
    "# stock_filepath = './drive/MyDrive/Colab Notebooks/data/bitamin_mini_project/netflix_60.csv'\n",
    "# news_filepath = './drive/MyDrive/Colab Notebooks/data/bitamin_mini_project/news_processed_filtered_2.csv'\n",
    "loader = PrepareData(stock_filepath, news_filepath)\n",
    "stock_df, news_df=loader.load_data() # >> 감성분석 미포함으로 모델 돌릴 땐 stock_df 바로 사용하면 됨\n",
    "total_df = loader.merging(stock=stock_df, news=news_df) # 주식데이터셋에 감성분석,토픽 포함시킨 전체 데이터셋\n",
    "\n",
    "stock_df.index = stock_df[\"Date\"]\n",
    "stock_df.drop(columns = \"Date\", inplace = True)\n",
    "stock_df[\"PINS\"].fillna(24.99, inplace = True)\n",
    "total_df.index = total_df[\"Date\"]\n",
    "total_df.drop(columns = \"Date\", inplace = True)\n",
    "total_df[\"PINS\"].fillna(24.99, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "956bfbf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T20:00:50.838960Z",
     "start_time": "2024-02-21T20:00:50.810078Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>target</th>\n",
       "      <th>seq_size</th>\n",
       "      <th>pred_size</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>best_val_loss</th>\n",
       "      <th>mean_error_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data  target  seq_size  pred_size  batch_size  hidden_size  best_val_loss  \\\n",
       "0     0       0         0          0           0            0              0   \n",
       "\n",
       "   mean_error_ratio  \n",
       "0                 0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame({\n",
    "    'data':[0],\n",
    "    'target':[0],\n",
    "    'seq_size':[0],\n",
    "    'pred_size':[0],\n",
    "    'batch_size':[0],\n",
    "    'hidden_size':[0],\n",
    "    'best_val_loss':[0],\n",
    "    'mean_error_ratio':[0]\n",
    "})\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72e804a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef3a74ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-20T15:03:57.362167Z",
     "start_time": "2024-02-20T05:32:43.139496Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔸START - total_df_Close_seq30_batch1_hidden64🔸\n",
      "Epoch 20/1000, Train Loss: 26.7503, Validation Loss: 23.8937\n",
      "Epoch 40/1000, Train Loss: 21.7205, Validation Loss: 19.8776\n",
      "Epoch 00051: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 60/1000, Train Loss: 19.4973, Validation Loss: 18.1150\n",
      "Epoch 80/1000, Train Loss: 18.6441, Validation Loss: 17.4605\n",
      "Epoch 00090: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Best validation loss : 17.283372642563993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [16:38, 998.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 7.70%\n",
      "🔸START - total_df_Close_seq30_batch1_hidden128🔸\n",
      "Epoch 20/1000, Train Loss: 25.7851, Validation Loss: 20.4350\n",
      "Epoch 40/1000, Train Loss: 21.4716, Validation Loss: 22.4750\n",
      "Epoch 00049: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 60/1000, Train Loss: 18.9022, Validation Loss: 19.1728\n",
      "Epoch 80/1000, Train Loss: 18.4786, Validation Loss: 17.9376\n",
      "Epoch 100/1000, Train Loss: 18.1583, Validation Loss: 18.4540\n",
      "Epoch 00104: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Best validation loss : 17.014774048914674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [35:13, 1066.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 3.40%\n",
      "🔸START - total_df_Close_seq30_batch4_hidden64🔸\n",
      "Epoch 20/1000, Train Loss: 34.8621, Validation Loss: 30.9172\n",
      "Epoch 40/1000, Train Loss: 25.2223, Validation Loss: 20.9943\n",
      "Epoch 60/1000, Train Loss: 22.3797, Validation Loss: 20.6795\n",
      "Epoch 80/1000, Train Loss: 20.5345, Validation Loss: 19.7337\n",
      "Epoch 100/1000, Train Loss: 19.3605, Validation Loss: 18.5914\n",
      "Epoch 120/1000, Train Loss: 17.9504, Validation Loss: 18.3018\n",
      "Epoch 140/1000, Train Loss: 18.2749, Validation Loss: 17.0301\n",
      "Epoch 00145: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 160/1000, Train Loss: 16.2663, Validation Loss: 15.7108\n",
      "Epoch 180/1000, Train Loss: 16.1236, Validation Loss: 15.4973\n",
      "Epoch 200/1000, Train Loss: 15.8741, Validation Loss: 15.6979\n",
      "Epoch 00201: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Best validation loss : 15.497323020559843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [44:54, 844.97s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 5.45%\n",
      "🔸START - total_df_Close_seq30_batch4_hidden128🔸\n",
      "Epoch 20/1000, Train Loss: 57.9154, Validation Loss: 52.8958\n",
      "Epoch 40/1000, Train Loss: 56.4172, Validation Loss: 51.0429\n",
      "Epoch 60/1000, Train Loss: 54.9630, Validation Loss: 50.1027\n",
      "Epoch 80/1000, Train Loss: 53.4716, Validation Loss: 47.2023\n",
      "Epoch 100/1000, Train Loss: 52.6546, Validation Loss: 45.8031\n",
      "Epoch 00107: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best validation loss : 45.00869416408852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [49:53, 629.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 13.52%\n",
      "🔸START - total_df_Close_seq30_batch8_hidden64🔸\n",
      "Epoch 20/1000, Train Loss: 37.9787, Validation Loss: 35.2732\n",
      "Epoch 40/1000, Train Loss: 24.7312, Validation Loss: 23.9364\n",
      "Epoch 60/1000, Train Loss: 22.5325, Validation Loss: 21.2757\n",
      "Epoch 80/1000, Train Loss: 20.1951, Validation Loss: 19.5952\n",
      "Epoch 100/1000, Train Loss: 18.6549, Validation Loss: 17.8472\n",
      "Epoch 00119: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 120/1000, Train Loss: 17.5533, Validation Loss: 16.4551\n",
      "Epoch 140/1000, Train Loss: 16.9599, Validation Loss: 16.1836\n",
      "Epoch 160/1000, Train Loss: 16.6466, Validation Loss: 16.0281\n",
      "Epoch 00174: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 180/1000, Train Loss: 16.4419, Validation Loss: 15.7302\n",
      "Best validation loss : 15.610622498296923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [53:56, 490.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 3.25%\n",
      "🔸START - total_df_Close_seq30_batch8_hidden128🔸\n",
      "Epoch 20/1000, Train Loss: 44.6881, Validation Loss: 46.2712\n",
      "Epoch 40/1000, Train Loss: 43.5943, Validation Loss: 38.1852\n",
      "Epoch 00049: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 60/1000, Train Loss: 39.3648, Validation Loss: 36.2033\n",
      "Epoch 80/1000, Train Loss: 36.8139, Validation Loss: 34.8018\n",
      "Epoch 100/1000, Train Loss: 36.7359, Validation Loss: 34.8679\n",
      "Epoch 120/1000, Train Loss: 35.6998, Validation Loss: 34.4067\n",
      "Epoch 140/1000, Train Loss: 34.5904, Validation Loss: 33.9216\n",
      "Epoch 160/1000, Train Loss: 34.9218, Validation Loss: 34.7870\n",
      "Epoch 00164: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Best validation loss : 32.50407828054121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [57:45, 401.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 4.91%\n",
      "🔸START - total_df_Close_seq60_batch1_hidden64🔸\n",
      "Epoch 20/1000, Train Loss: 28.4024, Validation Loss: 28.1823\n",
      "Epoch 40/1000, Train Loss: 23.5833, Validation Loss: 21.5378\n",
      "Epoch 60/1000, Train Loss: 21.4548, Validation Loss: 24.7890\n",
      "Epoch 00073: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 80/1000, Train Loss: 19.3557, Validation Loss: 18.8906\n",
      "Epoch 100/1000, Train Loss: 18.6277, Validation Loss: 20.2823\n",
      "Epoch 00101: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Best validation loss : 18.890649241559647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [1:14:40, 602.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 6.10%\n",
      "🔸START - total_df_Close_seq60_batch1_hidden128🔸\n",
      "Epoch 20/1000, Train Loss: 24.3284, Validation Loss: 21.1709\n",
      "Epoch 40/1000, Train Loss: 21.4238, Validation Loss: 27.2321\n",
      "Epoch 60/1000, Train Loss: 20.8310, Validation Loss: 20.2366\n",
      "Epoch 80/1000, Train Loss: 19.7565, Validation Loss: 19.5772\n",
      "Epoch 00087: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best validation loss : 18.16400061835762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [1:30:18, 708.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 5.61%\n",
      "🔸START - total_df_Close_seq60_batch4_hidden64🔸\n",
      "Epoch 20/1000, Train Loss: 29.5051, Validation Loss: 27.1248\n",
      "Epoch 40/1000, Train Loss: 23.1335, Validation Loss: 21.2228\n",
      "Epoch 00049: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 60/1000, Train Loss: 19.4775, Validation Loss: 19.6575\n",
      "Epoch 80/1000, Train Loss: 19.3080, Validation Loss: 19.1597\n",
      "Epoch 00089: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Best validation loss : 18.65569987297058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [1:34:14, 560.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 1.91%\n",
      "🔸START - total_df_Close_seq60_batch4_hidden128🔸\n",
      "Epoch 20/1000, Train Loss: 70.9741, Validation Loss: 66.4347\n",
      "Epoch 40/1000, Train Loss: 64.1582, Validation Loss: 61.0904\n",
      "Epoch 60/1000, Train Loss: 57.8430, Validation Loss: 56.4094\n",
      "Epoch 80/1000, Train Loss: 57.4739, Validation Loss: 53.3925\n",
      "Epoch 100/1000, Train Loss: 55.7116, Validation Loss: 52.5318\n",
      "Epoch 00116: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 120/1000, Train Loss: 58.5081, Validation Loss: 54.0843\n",
      "Best validation loss : 47.50266717274984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [1:39:19, 481.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 14.09%\n",
      "🔸START - total_df_Close_seq60_batch8_hidden64🔸\n",
      "Epoch 20/1000, Train Loss: 39.5832, Validation Loss: 37.0180\n",
      "Epoch 40/1000, Train Loss: 27.0092, Validation Loss: 27.0201\n",
      "Epoch 60/1000, Train Loss: 22.2493, Validation Loss: 21.6787\n",
      "Epoch 80/1000, Train Loss: 20.9353, Validation Loss: 19.9152\n",
      "Epoch 100/1000, Train Loss: 19.5657, Validation Loss: 17.6208\n",
      "Epoch 120/1000, Train Loss: 17.8345, Validation Loss: 17.9565\n",
      "Epoch 00139: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 140/1000, Train Loss: 16.8125, Validation Loss: 16.3332\n",
      "Epoch 160/1000, Train Loss: 16.4004, Validation Loss: 16.0110\n",
      "Epoch 180/1000, Train Loss: 16.3084, Validation Loss: 16.1874\n",
      "Epoch 200/1000, Train Loss: 16.3084, Validation Loss: 16.0377\n",
      "Epoch 220/1000, Train Loss: 16.1230, Validation Loss: 15.8679\n",
      "Epoch 240/1000, Train Loss: 15.9487, Validation Loss: 15.7287\n",
      "Epoch 260/1000, Train Loss: 15.5906, Validation Loss: 15.7049\n",
      "Epoch 280/1000, Train Loss: 15.6645, Validation Loss: 15.6683\n",
      "Epoch 00295: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 300/1000, Train Loss: 15.4534, Validation Loss: 15.6100\n",
      "Best validation loss : 15.43215602238973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [1:45:36, 450.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 4.10%\n",
      "🔸START - total_df_Close_seq60_batch8_hidden128🔸\n",
      "Epoch 20/1000, Train Loss: 57.5326, Validation Loss: 54.3415\n",
      "Epoch 40/1000, Train Loss: 51.1061, Validation Loss: 47.5088\n",
      "Epoch 60/1000, Train Loss: 45.6935, Validation Loss: 49.3778\n",
      "Epoch 80/1000, Train Loss: 42.8755, Validation Loss: 39.0900\n",
      "Epoch 100/1000, Train Loss: 43.6974, Validation Loss: 43.9253\n",
      "Epoch 00112: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 120/1000, Train Loss: 40.6166, Validation Loss: 40.2026\n",
      "Best validation loss : 36.82058696746826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [1:48:08, 359.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 31.16%\n",
      "🔸START - total_df_Close_seq120_batch1_hidden64🔸\n",
      "Epoch 20/1000, Train Loss: 26.9244, Validation Loss: 25.6875\n",
      "Epoch 40/1000, Train Loss: 22.3554, Validation Loss: 21.8932\n",
      "Epoch 60/1000, Train Loss: 20.8179, Validation Loss: 21.4989\n",
      "Epoch 00068: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 80/1000, Train Loss: 18.8982, Validation Loss: 18.5516\n",
      "Epoch 100/1000, Train Loss: 18.6874, Validation Loss: 18.7575\n",
      "Epoch 00104: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Best validation loss : 17.598565201843734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [2:05:31, 566.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 6.11%\n",
      "🔸START - total_df_Close_seq120_batch1_hidden128🔸\n",
      "Epoch 20/1000, Train Loss: 23.4624, Validation Loss: 21.3769\n",
      "Epoch 40/1000, Train Loss: 21.0652, Validation Loss: 19.7906\n",
      "Epoch 60/1000, Train Loss: 20.4540, Validation Loss: 25.2245\n",
      "Epoch 00078: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 80/1000, Train Loss: 18.0395, Validation Loss: 18.9619\n",
      "Best validation loss : 17.11438445390853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "14it [2:18:32, 631.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 6.54%\n",
      "🔸START - total_df_Close_seq120_batch4_hidden64🔸\n",
      "Epoch 20/1000, Train Loss: 29.2967, Validation Loss: 24.3679\n",
      "Epoch 40/1000, Train Loss: 23.8657, Validation Loss: 20.3838\n",
      "Epoch 60/1000, Train Loss: 21.4442, Validation Loss: 19.3342\n",
      "Epoch 80/1000, Train Loss: 19.5148, Validation Loss: 16.6895\n",
      "Epoch 100/1000, Train Loss: 18.6143, Validation Loss: 18.3605\n",
      "Epoch 120/1000, Train Loss: 18.8723, Validation Loss: 17.0351\n",
      "Epoch 140/1000, Train Loss: 17.3117, Validation Loss: 16.7708\n",
      "Epoch 00159: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 160/1000, Train Loss: 16.2163, Validation Loss: 15.6707\n",
      "Epoch 180/1000, Train Loss: 15.2668, Validation Loss: 14.9957\n",
      "Epoch 200/1000, Train Loss: 14.9984, Validation Loss: 14.9583\n",
      "Epoch 220/1000, Train Loss: 14.9688, Validation Loss: 14.3265\n",
      "Epoch 00232: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 240/1000, Train Loss: 14.7081, Validation Loss: 14.4048\n",
      "Best validation loss : 14.167484191426059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "15it [2:28:17, 617.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 1.74%\n",
      "🔸START - total_df_Close_seq120_batch4_hidden128🔸\n",
      "Epoch 20/1000, Train Loss: 89.8150, Validation Loss: 71.2448\n",
      "Epoch 40/1000, Train Loss: 76.3686, Validation Loss: 75.2735\n",
      "Epoch 00053: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 60/1000, Train Loss: 71.8315, Validation Loss: 64.3284\n",
      "Epoch 80/1000, Train Loss: 65.6496, Validation Loss: 57.3204\n",
      "Epoch 100/1000, Train Loss: 62.6653, Validation Loss: 57.3431\n",
      "Epoch 120/1000, Train Loss: 58.9696, Validation Loss: 53.6774\n",
      "Epoch 140/1000, Train Loss: 57.6635, Validation Loss: 50.8527\n",
      "Epoch 160/1000, Train Loss: 56.4518, Validation Loss: 53.8391\n",
      "Epoch 00161: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Best validation loss : 50.85273401360763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "16it [2:35:15, 557.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 7.69%\n",
      "🔸START - total_df_Close_seq120_batch8_hidden64🔸\n",
      "Epoch 20/1000, Train Loss: 39.6452, Validation Loss: 35.2618\n",
      "Epoch 40/1000, Train Loss: 25.4344, Validation Loss: 22.1692\n",
      "Epoch 60/1000, Train Loss: 24.9116, Validation Loss: 21.4993\n",
      "Epoch 80/1000, Train Loss: 23.0138, Validation Loss: 19.5662\n",
      "Epoch 100/1000, Train Loss: 19.5895, Validation Loss: 17.1799\n",
      "Epoch 00108: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best validation loss : 16.852619335569184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "17it [2:37:33, 431.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 1.43%\n",
      "🔸START - total_df_Close_seq120_batch8_hidden128🔸\n",
      "Epoch 20/1000, Train Loss: 56.0492, Validation Loss: 48.2507\n",
      "Epoch 40/1000, Train Loss: 47.9780, Validation Loss: 44.7582\n",
      "Epoch 60/1000, Train Loss: 42.5631, Validation Loss: 37.1570\n",
      "Epoch 80/1000, Train Loss: 29.5956, Validation Loss: 29.5924\n",
      "Epoch 100/1000, Train Loss: 27.0871, Validation Loss: 23.6421\n",
      "Epoch 120/1000, Train Loss: 25.3385, Validation Loss: 23.5657\n",
      "Epoch 140/1000, Train Loss: 22.1621, Validation Loss: 24.4276\n",
      "Epoch 160/1000, Train Loss: 22.2656, Validation Loss: 21.3535\n",
      "Epoch 180/1000, Train Loss: 21.6501, Validation Loss: 19.6437\n",
      "Epoch 00182: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best validation loss : 18.937585238752693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "18it [2:42:02, 382.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 7.93%\n",
      "🔸START - total_df_1d_ROC_seq30_batch1_hidden64🔸\n",
      "Epoch 20/1000, Train Loss: 2.5374, Validation Loss: 2.3385\n",
      "Epoch 40/1000, Train Loss: 2.5218, Validation Loss: 2.3343\n",
      "Epoch 60/1000, Train Loss: 2.5134, Validation Loss: 2.3169\n",
      "Epoch 00076: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 80/1000, Train Loss: 2.5025, Validation Loss: 2.3116\n",
      "Epoch 100/1000, Train Loss: 2.4988, Validation Loss: 2.3097\n",
      "Epoch 00109: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Best validation loss : 2.3068390432439867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "19it [3:02:15, 631.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 1.75%\n",
      "🔸START - total_df_1d_ROC_seq30_batch1_hidden128🔸\n",
      "Epoch 20/1000, Train Loss: 2.5572, Validation Loss: 2.3591\n",
      "Epoch 40/1000, Train Loss: 2.5384, Validation Loss: 2.3391\n",
      "Epoch 60/1000, Train Loss: 2.5305, Validation Loss: 2.3358\n",
      "Epoch 80/1000, Train Loss: 2.5299, Validation Loss: 2.3372\n",
      "Epoch 00099: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 100/1000, Train Loss: 2.5200, Validation Loss: 2.3308\n",
      "Epoch 120/1000, Train Loss: 2.5149, Validation Loss: 2.3304\n",
      "Epoch 00124: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Best validation loss : 2.327614696055162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "20it [3:23:16, 820.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 1.98%\n",
      "🔸START - total_df_1d_ROC_seq30_batch4_hidden64🔸\n",
      "Epoch 20/1000, Train Loss: 2.7431, Validation Loss: 2.5345\n",
      "Epoch 40/1000, Train Loss: 2.6983, Validation Loss: 2.5397\n",
      "Epoch 00044: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best validation loss : 2.5244822853901345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "21it [3:25:29, 614.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 3.34%\n",
      "🔸START - total_df_1d_ROC_seq30_batch4_hidden128🔸\n",
      "Epoch 20/1000, Train Loss: 2.7968, Validation Loss: 2.5770\n",
      "Epoch 40/1000, Train Loss: 2.7822, Validation Loss: 2.5734\n",
      "Epoch 60/1000, Train Loss: 2.7722, Validation Loss: 2.5631\n",
      "Epoch 00071: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 80/1000, Train Loss: 2.7547, Validation Loss: 2.5635\n",
      "Epoch 00092: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 100/1000, Train Loss: 2.7544, Validation Loss: 2.5620\n",
      "Best validation loss : 2.558942188982104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "22it [3:30:04, 512.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 1.83%\n",
      "🔸START - total_df_1d_ROC_seq30_batch8_hidden64🔸\n",
      "Epoch 20/1000, Train Loss: 2.7677, Validation Loss: 2.6145\n",
      "Epoch 40/1000, Train Loss: 2.7249, Validation Loss: 2.6161\n",
      "Epoch 60/1000, Train Loss: 2.6362, Validation Loss: 2.6267\n",
      "Epoch 00062: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best validation loss : 2.576879132178522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "23it [3:31:34, 385.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 3.16%\n",
      "🔸START - total_df_1d_ROC_seq30_batch8_hidden128🔸\n",
      "Epoch 20/1000, Train Loss: 2.8099, Validation Loss: 2.6169\n",
      "Epoch 40/1000, Train Loss: 2.7793, Validation Loss: 2.6240\n",
      "Epoch 00044: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 60/1000, Train Loss: 2.7539, Validation Loss: 2.6204\n",
      "Epoch 00073: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 80/1000, Train Loss: 2.7356, Validation Loss: 2.6173\n",
      "Best validation loss : 2.6117514602599607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [3:33:20, 301.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 2.68%\n",
      "🔸START - total_df_1d_ROC_seq60_batch1_hidden64🔸\n",
      "Epoch 20/1000, Train Loss: 2.4987, Validation Loss: 2.5841\n",
      "Epoch 40/1000, Train Loss: 2.4866, Validation Loss: 2.5732\n",
      "Epoch 60/1000, Train Loss: 2.4761, Validation Loss: 2.5576\n",
      "Epoch 80/1000, Train Loss: 2.4678, Validation Loss: 2.5570\n",
      "Epoch 100/1000, Train Loss: 2.4660, Validation Loss: 2.5588\n",
      "Epoch 120/1000, Train Loss: 2.4628, Validation Loss: 2.5547\n",
      "Epoch 00124: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best validation loss : 2.548526588357797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "25it [3:54:46, 596.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 1.67%\n",
      "🔸START - total_df_1d_ROC_seq60_batch1_hidden128🔸\n",
      "Epoch 20/1000, Train Loss: 2.5036, Validation Loss: 2.5747\n",
      "Epoch 40/1000, Train Loss: 2.4891, Validation Loss: 2.5749\n",
      "Epoch 00056: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 60/1000, Train Loss: 2.4775, Validation Loss: 2.5681\n",
      "Best validation loss : 2.565921583345958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "26it [4:05:28, 610.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 1.99%\n",
      "🔸START - total_df_1d_ROC_seq60_batch4_hidden64🔸\n",
      "Epoch 20/1000, Train Loss: 2.6778, Validation Loss: 2.7829\n",
      "Epoch 40/1000, Train Loss: 2.6230, Validation Loss: 2.7575\n",
      "Epoch 60/1000, Train Loss: 2.5464, Validation Loss: 2.7579\n",
      "Epoch 00063: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best validation loss : 2.7480224609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "27it [4:08:38, 484.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 5.48%\n",
      "🔸START - total_df_1d_ROC_seq60_batch4_hidden128🔸\n",
      "Epoch 20/1000, Train Loss: 2.7402, Validation Loss: 2.8225\n",
      "Epoch 40/1000, Train Loss: 2.7280, Validation Loss: 2.8121\n",
      "Epoch 00048: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 60/1000, Train Loss: 2.7036, Validation Loss: 2.8031\n",
      "Epoch 00075: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 80/1000, Train Loss: 2.7053, Validation Loss: 2.8047\n",
      "Best validation loss : 2.8010415534178414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "28it [4:12:41, 411.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 2.06%\n",
      "🔸START - total_df_1d_ROC_seq60_batch8_hidden64🔸\n",
      "Epoch 20/1000, Train Loss: 2.7324, Validation Loss: 2.8781\n",
      "Epoch 40/1000, Train Loss: 2.6521, Validation Loss: 2.8660\n",
      "Epoch 00058: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 60/1000, Train Loss: 2.4716, Validation Loss: 2.9140\n",
      "Best validation loss : 2.8410502592722575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "29it [4:14:18, 317.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 5.28%\n",
      "🔸START - total_df_1d_ROC_seq60_batch8_hidden128🔸\n",
      "Epoch 20/1000, Train Loss: 2.7680, Validation Loss: 2.8759\n",
      "Epoch 40/1000, Train Loss: 2.7571, Validation Loss: 2.8630\n",
      "Epoch 60/1000, Train Loss: 2.7485, Validation Loss: 2.8694\n",
      "Epoch 00067: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 80/1000, Train Loss: 2.6710, Validation Loss: 2.8379\n",
      "Epoch 100/1000, Train Loss: 2.6459, Validation Loss: 2.8351\n",
      "Epoch 120/1000, Train Loss: 2.6217, Validation Loss: 2.8387\n",
      "Epoch 00131: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 140/1000, Train Loss: 2.6189, Validation Loss: 2.8320\n",
      "Best validation loss : 2.826374117533366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "30it [4:17:34, 280.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 4.02%\n",
      "🔸START - total_df_1d_ROC_seq120_batch1_hidden64🔸\n",
      "Epoch 20/1000, Train Loss: 2.5839, Validation Loss: 2.5410\n",
      "Epoch 40/1000, Train Loss: 2.5809, Validation Loss: 2.5379\n",
      "Epoch 00045: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best validation loss : 2.535277021405971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "31it [4:26:34, 358.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 2.30%\n",
      "🔸START - total_df_1d_ROC_seq120_batch1_hidden128🔸\n",
      "Epoch 20/1000, Train Loss: 2.5838, Validation Loss: 2.5425\n",
      "Epoch 00031: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 40/1000, Train Loss: 2.5807, Validation Loss: 2.5403\n",
      "Best validation loss : 2.5379980884294593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "32it [4:33:24, 374.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 2.07%\n",
      "🔸START - total_df_1d_ROC_seq120_batch4_hidden64🔸\n",
      "Epoch 20/1000, Train Loss: 2.7728, Validation Loss: 2.7200\n",
      "Epoch 40/1000, Train Loss: 2.7017, Validation Loss: 2.7171\n",
      "Epoch 60/1000, Train Loss: 2.6205, Validation Loss: 2.7057\n",
      "Epoch 00080: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 80/1000, Train Loss: 2.5922, Validation Loss: 2.7483\n",
      "Best validation loss : 2.678681354773672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "33it [4:37:15, 331.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 4.78%\n",
      "🔸START - total_df_1d_ROC_seq120_batch4_hidden128🔸\n",
      "Epoch 20/1000, Train Loss: 2.8312, Validation Loss: 2.7831\n",
      "Epoch 40/1000, Train Loss: 2.8225, Validation Loss: 2.7796\n",
      "Epoch 60/1000, Train Loss: 2.8255, Validation Loss: 2.7866\n",
      "Epoch 00065: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best validation loss : 2.772581094189694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "34it [4:40:44, 294.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 2.06%\n",
      "🔸START - total_df_1d_ROC_seq120_batch8_hidden64🔸\n",
      "Epoch 20/1000, Train Loss: 2.8214, Validation Loss: 2.7924\n",
      "Epoch 40/1000, Train Loss: 2.7242, Validation Loss: 2.7717\n",
      "Epoch 60/1000, Train Loss: 2.6599, Validation Loss: 2.8385\n",
      "Epoch 00061: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best validation loss : 2.7717379578228654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "35it [4:42:14, 233.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 4.81%\n",
      "🔸START - total_df_1d_ROC_seq120_batch8_hidden128🔸\n",
      "Epoch 20/1000, Train Loss: 2.8571, Validation Loss: 2.8374\n",
      "Epoch 40/1000, Train Loss: 2.8535, Validation Loss: 2.8172\n",
      "Epoch 60/1000, Train Loss: 2.8589, Validation Loss: 2.8191\n",
      "Epoch 80/1000, Train Loss: 2.8140, Validation Loss: 2.7966\n",
      "Epoch 100/1000, Train Loss: 2.8365, Validation Loss: 2.7953\n",
      "Epoch 00102: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best validation loss : 2.784962641781774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "36it [4:44:50, 210.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 2.61%\n",
      "🔸START - stock_df_Close_seq30_batch1_hidden64🔸\n",
      "Epoch 20/1000, Train Loss: 26.4013, Validation Loss: 23.0145\n",
      "Epoch 40/1000, Train Loss: 21.4392, Validation Loss: 20.7359\n",
      "Epoch 60/1000, Train Loss: 20.2653, Validation Loss: 18.6598\n",
      "Epoch 00075: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 80/1000, Train Loss: 18.2338, Validation Loss: 17.7103\n",
      "Epoch 100/1000, Train Loss: 17.9811, Validation Loss: 17.9538\n",
      "Epoch 00114: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 120/1000, Train Loss: 17.4146, Validation Loss: 17.3754\n",
      "Best validation loss : 16.792565629130504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "37it [5:05:05, 511.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 7.86%\n",
      "🔸START - stock_df_Close_seq30_batch1_hidden128🔸\n",
      "Epoch 20/1000, Train Loss: 22.2669, Validation Loss: 19.6869\n",
      "Epoch 00040: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 40/1000, Train Loss: 20.8405, Validation Loss: 22.1090\n",
      "Epoch 60/1000, Train Loss: 18.4402, Validation Loss: 17.8327\n",
      "Epoch 00079: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 80/1000, Train Loss: 17.8553, Validation Loss: 17.9218\n",
      "Best validation loss : 17.177685378027743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "38it [5:20:05, 628.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 13.11%\n",
      "🔸START - stock_df_Close_seq30_batch4_hidden64🔸\n",
      "Epoch 20/1000, Train Loss: 31.7616, Validation Loss: 26.1964\n",
      "Epoch 40/1000, Train Loss: 23.2089, Validation Loss: 20.4605\n",
      "Epoch 60/1000, Train Loss: 20.9192, Validation Loss: 18.5186\n",
      "Epoch 80/1000, Train Loss: 19.4200, Validation Loss: 18.5722\n",
      "Epoch 100/1000, Train Loss: 19.0175, Validation Loss: 39.4428\n",
      "Epoch 120/1000, Train Loss: 19.0024, Validation Loss: 17.4897\n",
      "Epoch 140/1000, Train Loss: 16.9005, Validation Loss: 16.0424\n",
      "Epoch 160/1000, Train Loss: 16.9236, Validation Loss: 15.7942\n",
      "Epoch 00163: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 180/1000, Train Loss: 15.8402, Validation Loss: 15.6798\n",
      "Epoch 200/1000, Train Loss: 15.6498, Validation Loss: 15.4638\n",
      "Epoch 220/1000, Train Loss: 15.7657, Validation Loss: 15.6585\n",
      "Epoch 00235: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 240/1000, Train Loss: 15.4928, Validation Loss: 15.3794\n",
      "Best validation loss : 15.042849837756547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "39it [5:31:36, 647.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 8.08%\n",
      "🔸START - stock_df_Close_seq30_batch4_hidden128🔸\n",
      "Epoch 20/1000, Train Loss: 42.7927, Validation Loss: 38.9935\n",
      "Epoch 40/1000, Train Loss: 40.1579, Validation Loss: 38.2088\n",
      "Epoch 60/1000, Train Loss: 39.6197, Validation Loss: 37.6984\n",
      "Epoch 80/1000, Train Loss: 34.0476, Validation Loss: 32.2820\n",
      "Epoch 100/1000, Train Loss: 30.3776, Validation Loss: 29.9238\n",
      "Epoch 120/1000, Train Loss: 26.9942, Validation Loss: 21.8288\n",
      "Epoch 140/1000, Train Loss: 26.7978, Validation Loss: 24.3143\n",
      "Epoch 160/1000, Train Loss: 22.6370, Validation Loss: 25.5537\n",
      "Epoch 00176: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 180/1000, Train Loss: 20.2654, Validation Loss: 20.9223\n",
      "Best validation loss : 19.585641509196797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "40it [5:40:14, 608.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 17.15%\n",
      "🔸START - stock_df_Close_seq30_batch8_hidden64🔸\n",
      "Epoch 20/1000, Train Loss: 36.9816, Validation Loss: 35.4673\n",
      "Epoch 40/1000, Train Loss: 24.5378, Validation Loss: 21.4607\n",
      "Epoch 60/1000, Train Loss: 21.7382, Validation Loss: 21.5349\n",
      "Epoch 80/1000, Train Loss: 20.2806, Validation Loss: 18.5050\n",
      "Epoch 100/1000, Train Loss: 19.0546, Validation Loss: 18.0175\n",
      "Epoch 120/1000, Train Loss: 17.6194, Validation Loss: 16.2824\n",
      "Epoch 140/1000, Train Loss: 16.9164, Validation Loss: 16.7774\n",
      "Epoch 160/1000, Train Loss: 16.5408, Validation Loss: 15.9199\n",
      "Epoch 180/1000, Train Loss: 15.6158, Validation Loss: 15.3786\n",
      "Epoch 200/1000, Train Loss: 14.7514, Validation Loss: 14.5199\n",
      "Epoch 220/1000, Train Loss: 14.7602, Validation Loss: 13.8662\n",
      "Epoch 240/1000, Train Loss: 13.2543, Validation Loss: 12.7283\n",
      "Epoch 00260: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 260/1000, Train Loss: 13.2222, Validation Loss: 12.2752\n",
      "Epoch 280/1000, Train Loss: 11.6559, Validation Loss: 11.4897\n",
      "Epoch 300/1000, Train Loss: 11.8792, Validation Loss: 11.4970\n",
      "Epoch 320/1000, Train Loss: 11.6490, Validation Loss: 10.9391\n",
      "Epoch 340/1000, Train Loss: 11.6449, Validation Loss: 11.0009\n",
      "Epoch 00342: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Best validation loss : 10.861655789036904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "41it [5:48:25, 573.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 5.12%\n",
      "🔸START - stock_df_Close_seq30_batch8_hidden128🔸\n",
      "Epoch 20/1000, Train Loss: 47.5543, Validation Loss: 42.4421\n",
      "Epoch 40/1000, Train Loss: 44.2238, Validation Loss: 40.5886\n",
      "Epoch 60/1000, Train Loss: 45.9839, Validation Loss: 39.2368\n",
      "Epoch 80/1000, Train Loss: 41.0086, Validation Loss: 38.6241\n",
      "Epoch 100/1000, Train Loss: 39.6669, Validation Loss: 39.8842\n",
      "Epoch 120/1000, Train Loss: 37.7398, Validation Loss: 35.8219\n",
      "Epoch 140/1000, Train Loss: 31.4723, Validation Loss: 27.9727\n",
      "Epoch 160/1000, Train Loss: 32.5567, Validation Loss: 27.8753\n",
      "Epoch 180/1000, Train Loss: 29.6212, Validation Loss: 24.6023\n",
      "Epoch 200/1000, Train Loss: 26.8395, Validation Loss: 23.8511\n",
      "Epoch 220/1000, Train Loss: 26.3595, Validation Loss: 22.0067\n",
      "Epoch 240/1000, Train Loss: 25.5496, Validation Loss: 22.0169\n",
      "Epoch 00247: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best validation loss : 20.800246546345374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "42it [5:54:24, 508.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 3.79%\n",
      "🔸START - stock_df_Close_seq60_batch1_hidden64🔸\n",
      "Epoch 20/1000, Train Loss: 25.3575, Validation Loss: 24.4391\n",
      "Epoch 40/1000, Train Loss: 23.7402, Validation Loss: 24.0495\n",
      "Epoch 00047: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 60/1000, Train Loss: 20.1117, Validation Loss: 18.4421\n",
      "Epoch 80/1000, Train Loss: 19.7177, Validation Loss: 18.3499\n",
      "Epoch 00084: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Best validation loss : 17.81054071919257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "43it [6:09:39, 630.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 4.73%\n",
      "🔸START - stock_df_Close_seq60_batch1_hidden128🔸\n",
      "Epoch 20/1000, Train Loss: 22.7374, Validation Loss: 22.7155\n",
      "Epoch 40/1000, Train Loss: 20.7515, Validation Loss: 22.5191\n",
      "Epoch 60/1000, Train Loss: 19.3024, Validation Loss: 18.3872\n",
      "Epoch 80/1000, Train Loss: 18.5711, Validation Loss: 17.4270\n",
      "Epoch 100/1000, Train Loss: 18.2677, Validation Loss: 20.2789\n",
      "Epoch 00101: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best validation loss : 17.42701150789982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "44it [6:28:08, 774.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 18.95%\n",
      "🔸START - stock_df_Close_seq60_batch4_hidden64🔸\n",
      "Epoch 20/1000, Train Loss: 29.7485, Validation Loss: 25.5965\n",
      "Epoch 40/1000, Train Loss: 23.2834, Validation Loss: 25.5343\n",
      "Epoch 00048: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 60/1000, Train Loss: 19.8724, Validation Loss: 18.5983\n",
      "Epoch 00074: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 80/1000, Train Loss: 19.2403, Validation Loss: 18.8011\n",
      "Best validation loss : 18.340510773658753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "45it [6:31:53, 609.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 7.92%\n",
      "🔸START - stock_df_Close_seq60_batch4_hidden128🔸\n",
      "Epoch 20/1000, Train Loss: 56.6469, Validation Loss: 51.5189\n",
      "Epoch 40/1000, Train Loss: 46.4001, Validation Loss: 42.5925\n",
      "Epoch 60/1000, Train Loss: 42.6785, Validation Loss: 43.8416\n",
      "Epoch 80/1000, Train Loss: 40.2428, Validation Loss: 40.6355\n",
      "Epoch 00090: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best validation loss : 33.44006641705831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "46it [6:36:24, 507.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 5.99%\n",
      "🔸START - stock_df_Close_seq60_batch8_hidden64🔸\n",
      "Epoch 20/1000, Train Loss: 36.3920, Validation Loss: 30.7222\n",
      "Epoch 40/1000, Train Loss: 24.9983, Validation Loss: 22.2198\n",
      "Epoch 60/1000, Train Loss: 22.0269, Validation Loss: 22.3800\n",
      "Epoch 80/1000, Train Loss: 20.6068, Validation Loss: 21.4364\n",
      "Epoch 100/1000, Train Loss: 18.8865, Validation Loss: 18.7992\n",
      "Epoch 00119: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 120/1000, Train Loss: 17.6600, Validation Loss: 16.9764\n",
      "Epoch 140/1000, Train Loss: 16.9022, Validation Loss: 16.6000\n",
      "Epoch 160/1000, Train Loss: 16.7798, Validation Loss: 16.3914\n",
      "Epoch 00172: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 180/1000, Train Loss: 16.6122, Validation Loss: 16.5037\n",
      "Best validation loss : 16.277138710021973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "47it [6:40:31, 429.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 4.84%\n",
      "🔸START - stock_df_Close_seq60_batch8_hidden128🔸\n",
      "Epoch 20/1000, Train Loss: 46.9658, Validation Loss: 39.0262\n",
      "Epoch 40/1000, Train Loss: 42.1984, Validation Loss: 41.0908\n",
      "Epoch 60/1000, Train Loss: 40.2955, Validation Loss: 38.3066\n",
      "Epoch 00066: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 80/1000, Train Loss: 31.2761, Validation Loss: 29.8008\n",
      "Epoch 100/1000, Train Loss: 29.1798, Validation Loss: 26.8573\n",
      "Epoch 120/1000, Train Loss: 26.6599, Validation Loss: 25.5580\n",
      "Epoch 140/1000, Train Loss: 26.8212, Validation Loss: 25.4737\n",
      "Epoch 00145: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Best validation loss : 24.866155942281086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "48it [6:44:00, 363.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 3.16%\n",
      "🔸START - stock_df_Close_seq120_batch1_hidden64🔸\n",
      "Epoch 20/1000, Train Loss: 25.6477, Validation Loss: 23.5019\n",
      "Epoch 40/1000, Train Loss: 22.8460, Validation Loss: 19.0933\n",
      "Epoch 60/1000, Train Loss: 21.3757, Validation Loss: 24.3946\n",
      "Epoch 80/1000, Train Loss: 21.4477, Validation Loss: 18.1733\n",
      "Epoch 00084: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best validation loss : 16.945223567760095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "49it [6:58:36, 517.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 2.80%\n",
      "🔸START - stock_df_Close_seq120_batch1_hidden128🔸\n",
      "Epoch 20/1000, Train Loss: 24.3814, Validation Loss: 22.3590\n",
      "Epoch 40/1000, Train Loss: 21.3716, Validation Loss: 23.8381\n",
      "Epoch 60/1000, Train Loss: 20.2354, Validation Loss: 20.1577\n",
      "Epoch 80/1000, Train Loss: 19.4228, Validation Loss: 18.9578\n",
      "Epoch 00095: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 100/1000, Train Loss: 17.2886, Validation Loss: 19.2250\n",
      "Best validation loss : 17.601028774691894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "50it [7:15:03, 658.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 2.37%\n",
      "🔸START - stock_df_Close_seq120_batch4_hidden64🔸\n",
      "Epoch 20/1000, Train Loss: 37.9719, Validation Loss: 32.1727\n",
      "Epoch 40/1000, Train Loss: 26.6472, Validation Loss: 22.1831\n",
      "Epoch 60/1000, Train Loss: 23.0431, Validation Loss: 20.7125\n",
      "Epoch 80/1000, Train Loss: 21.5914, Validation Loss: 17.6055\n",
      "Epoch 100/1000, Train Loss: 19.7449, Validation Loss: 18.5184\n",
      "Epoch 120/1000, Train Loss: 18.4310, Validation Loss: 17.4962\n",
      "Epoch 00136: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 140/1000, Train Loss: 16.8981, Validation Loss: 17.7785\n",
      "Best validation loss : 16.42557532327217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "51it [7:21:05, 569.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 8.69%\n",
      "🔸START - stock_df_Close_seq120_batch4_hidden128🔸\n",
      "Epoch 20/1000, Train Loss: 51.1909, Validation Loss: 52.2963\n",
      "Epoch 40/1000, Train Loss: 48.6654, Validation Loss: 44.7150\n",
      "Epoch 60/1000, Train Loss: 46.7743, Validation Loss: 45.2056\n",
      "Epoch 80/1000, Train Loss: 43.0190, Validation Loss: 39.1175\n",
      "Epoch 100/1000, Train Loss: 39.3097, Validation Loss: 36.3810\n",
      "Epoch 00112: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 120/1000, Train Loss: 39.3949, Validation Loss: 35.4536\n",
      "Best validation loss : 33.50418544233891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "52it [7:26:24, 494.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 1.43%\n",
      "🔸START - stock_df_Close_seq120_batch8_hidden64🔸\n",
      "Epoch 20/1000, Train Loss: 37.4005, Validation Loss: 34.0049\n",
      "Epoch 40/1000, Train Loss: 24.7118, Validation Loss: 23.0518\n",
      "Epoch 60/1000, Train Loss: 21.9942, Validation Loss: 20.0995\n",
      "Epoch 80/1000, Train Loss: 19.7463, Validation Loss: 19.2502\n",
      "Epoch 100/1000, Train Loss: 18.9574, Validation Loss: 17.4136\n",
      "Epoch 120/1000, Train Loss: 18.7009, Validation Loss: 18.1388\n",
      "Epoch 140/1000, Train Loss: 17.6163, Validation Loss: 16.9754\n",
      "Epoch 160/1000, Train Loss: 17.2837, Validation Loss: 16.4294\n",
      "Epoch 00172: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 180/1000, Train Loss: 16.2013, Validation Loss: 15.8730\n",
      "Epoch 200/1000, Train Loss: 16.1032, Validation Loss: 15.6633\n",
      "Epoch 220/1000, Train Loss: 16.0841, Validation Loss: 15.2015\n",
      "Epoch 240/1000, Train Loss: 15.6386, Validation Loss: 15.1383\n",
      "Epoch 260/1000, Train Loss: 15.6862, Validation Loss: 15.0298\n",
      "Epoch 280/1000, Train Loss: 15.4417, Validation Loss: 14.8549\n",
      "Epoch 300/1000, Train Loss: 15.4571, Validation Loss: 14.9754\n",
      "Epoch 00316: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 320/1000, Train Loss: 15.1458, Validation Loss: 14.8680\n",
      "Best validation loss : 14.590413455305429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "53it [7:33:26, 472.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 5.03%\n",
      "🔸START - stock_df_Close_seq120_batch8_hidden128🔸\n",
      "Epoch 20/1000, Train Loss: 60.7325, Validation Loss: 58.3824\n",
      "Epoch 40/1000, Train Loss: 47.7799, Validation Loss: 42.1567\n",
      "Epoch 60/1000, Train Loss: 46.7484, Validation Loss: 45.7001\n",
      "Epoch 00062: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best validation loss : 40.23746385245487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "54it [7:35:12, 362.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 2.08%\n",
      "🔸START - stock_df_1d_ROC_seq30_batch1_hidden64🔸\n",
      "Epoch 20/1000, Train Loss: 2.5473, Validation Loss: 2.3464\n",
      "Epoch 40/1000, Train Loss: 2.5254, Validation Loss: 2.3398\n",
      "Epoch 60/1000, Train Loss: 2.5189, Validation Loss: 2.3318\n",
      "Epoch 80/1000, Train Loss: 2.5124, Validation Loss: 2.3216\n",
      "Epoch 100/1000, Train Loss: 2.5046, Validation Loss: 2.3103\n",
      "Epoch 120/1000, Train Loss: 2.4999, Validation Loss: 2.3110\n",
      "Epoch 140/1000, Train Loss: 2.5023, Validation Loss: 2.3096\n",
      "Epoch 160/1000, Train Loss: 2.4949, Validation Loss: 2.3065\n",
      "Epoch 00162: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best validation loss : 2.3033851973834585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "55it [8:06:02, 808.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 1.77%\n",
      "🔸START - stock_df_1d_ROC_seq30_batch1_hidden128🔸\n",
      "Epoch 20/1000, Train Loss: 2.5578, Validation Loss: 2.3556\n",
      "Epoch 00029: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best validation loss : 2.3532597510541073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "56it [8:12:55, 690.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 2.18%\n",
      "🔸START - stock_df_1d_ROC_seq30_batch4_hidden64🔸\n",
      "Epoch 20/1000, Train Loss: 2.7209, Validation Loss: 2.5385\n",
      "Epoch 40/1000, Train Loss: 2.6869, Validation Loss: 2.5369\n",
      "Epoch 60/1000, Train Loss: 2.6343, Validation Loss: 2.5101\n",
      "Epoch 80/1000, Train Loss: 2.5709, Validation Loss: 2.5231\n",
      "Epoch 00098: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 100/1000, Train Loss: 2.4622, Validation Loss: 2.5115\n",
      "Best validation loss : 2.47863998569426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "57it [8:17:51, 571.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 3.87%\n",
      "🔸START - stock_df_1d_ROC_seq30_batch4_hidden128🔸\n",
      "Epoch 20/1000, Train Loss: 2.7765, Validation Loss: 2.5677\n",
      "Epoch 40/1000, Train Loss: 2.7432, Validation Loss: 2.5410\n",
      "Epoch 60/1000, Train Loss: 2.7489, Validation Loss: 2.5659\n",
      "Epoch 00061: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best validation loss : 2.540998390463532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "58it [8:21:09, 459.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 2.17%\n",
      "🔸START - stock_df_1d_ROC_seq30_batch8_hidden64🔸\n",
      "Epoch 20/1000, Train Loss: 2.7786, Validation Loss: 2.6161\n",
      "Epoch 40/1000, Train Loss: 2.7371, Validation Loss: 2.6127\n",
      "Epoch 60/1000, Train Loss: 2.6533, Validation Loss: 2.5854\n",
      "Epoch 80/1000, Train Loss: 2.5592, Validation Loss: 2.6519\n",
      "Epoch 00081: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best validation loss : 2.585373059395821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "59it [8:23:12, 358.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 4.58%\n",
      "🔸START - stock_df_1d_ROC_seq30_batch8_hidden128🔸\n",
      "Epoch 20/1000, Train Loss: 2.8076, Validation Loss: 2.6442\n",
      "Epoch 40/1000, Train Loss: 2.7907, Validation Loss: 2.6151\n",
      "Epoch 00047: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best validation loss : 2.6008129004509217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "60it [8:24:31, 274.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 2.07%\n",
      "🔸START - stock_df_1d_ROC_seq60_batch1_hidden64🔸\n",
      "Epoch 20/1000, Train Loss: 2.4963, Validation Loss: 2.5695\n",
      "Epoch 40/1000, Train Loss: 2.4871, Validation Loss: 2.5650\n",
      "Epoch 00053: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 60/1000, Train Loss: 2.4712, Validation Loss: 2.5684\n",
      "Best validation loss : 2.5644796352927424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "61it [8:34:30, 371.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 1.97%\n",
      "🔸START - stock_df_1d_ROC_seq60_batch1_hidden128🔸\n",
      "Epoch 20/1000, Train Loss: 2.5242, Validation Loss: 2.6010\n",
      "Epoch 00026: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best validation loss : 2.5969300823552266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "62it [8:40:22, 365.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 1.92%\n",
      "🔸START - stock_df_1d_ROC_seq60_batch4_hidden64🔸\n",
      "Epoch 20/1000, Train Loss: 2.7010, Validation Loss: 2.8102\n",
      "Epoch 40/1000, Train Loss: 2.6093, Validation Loss: 2.7699\n",
      "Epoch 60/1000, Train Loss: 2.5534, Validation Loss: 2.7658\n",
      "Epoch 00072: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 80/1000, Train Loss: 2.4477, Validation Loss: 2.7770\n",
      "Best validation loss : 2.743750176827113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "63it [8:44:05, 323.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 4.68%\n",
      "🔸START - stock_df_1d_ROC_seq60_batch4_hidden128🔸\n",
      "Epoch 20/1000, Train Loss: 2.7330, Validation Loss: 2.8236\n",
      "Epoch 40/1000, Train Loss: 2.7235, Validation Loss: 2.8079\n",
      "Epoch 00051: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 60/1000, Train Loss: 2.7123, Validation Loss: 2.7986\n",
      "Epoch 80/1000, Train Loss: 2.6875, Validation Loss: 2.7909\n",
      "Epoch 100/1000, Train Loss: 2.6936, Validation Loss: 2.7850\n",
      "Epoch 120/1000, Train Loss: 2.6835, Validation Loss: 2.7879\n",
      "Epoch 00121: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Best validation loss : 2.7850069721539814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "64it [8:49:48, 328.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 1.70%\n",
      "🔸START - stock_df_1d_ROC_seq60_batch8_hidden64🔸\n",
      "Epoch 20/1000, Train Loss: 2.7466, Validation Loss: 2.8791\n",
      "Epoch 40/1000, Train Loss: 2.6747, Validation Loss: 2.8697\n",
      "Epoch 00051: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 60/1000, Train Loss: 2.5441, Validation Loss: 2.8689\n",
      "Best validation loss : 2.8439644455909727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "65it [8:51:01, 252.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 3.41%\n",
      "🔸START - stock_df_1d_ROC_seq60_batch8_hidden128🔸\n",
      "Epoch 20/1000, Train Loss: 2.7721, Validation Loss: 2.8802\n",
      "Epoch 40/1000, Train Loss: 2.7627, Validation Loss: 2.8893\n",
      "Epoch 00042: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best validation loss : 2.8618611097335815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "66it [8:52:06, 196.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 2.46%\n",
      "🔸START - stock_df_1d_ROC_seq120_batch1_hidden64🔸\n",
      "Epoch 20/1000, Train Loss: 2.5733, Validation Loss: 2.5387\n",
      "Epoch 40/1000, Train Loss: 2.5563, Validation Loss: 2.5210\n",
      "Epoch 60/1000, Train Loss: 2.5433, Validation Loss: 2.5031\n",
      "Epoch 80/1000, Train Loss: 2.5423, Validation Loss: 2.5046\n",
      "Epoch 00087: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 100/1000, Train Loss: 2.5310, Validation Loss: 2.4941\n",
      "Epoch 00116: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 120/1000, Train Loss: 2.5281, Validation Loss: 2.4937\n",
      "Best validation loss : 2.4929736636381232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "67it [9:10:52, 475.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 1.73%\n",
      "🔸START - stock_df_1d_ROC_seq120_batch1_hidden128🔸\n",
      "Epoch 20/1000, Train Loss: 2.5839, Validation Loss: 2.5379\n",
      "Epoch 00036: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 40/1000, Train Loss: 2.5816, Validation Loss: 2.5402\n",
      "Best validation loss : 2.537312366793641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "68it [9:17:43, 455.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 2.04%\n",
      "🔸START - stock_df_1d_ROC_seq120_batch4_hidden64🔸\n",
      "Epoch 20/1000, Train Loss: 2.7668, Validation Loss: 2.7089\n",
      "Epoch 40/1000, Train Loss: 2.7235, Validation Loss: 2.7116\n",
      "Epoch 60/1000, Train Loss: 2.6592, Validation Loss: 2.6984\n",
      "Epoch 80/1000, Train Loss: 2.6032, Validation Loss: 2.7041\n",
      "Epoch 00087: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best validation loss : 2.6655864506437066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "69it [9:21:52, 393.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 4.16%\n",
      "🔸START - stock_df_1d_ROC_seq120_batch4_hidden128🔸\n",
      "Epoch 20/1000, Train Loss: 2.8185, Validation Loss: 2.7598\n",
      "Epoch 40/1000, Train Loss: 2.8089, Validation Loss: 2.7580\n",
      "Epoch 60/1000, Train Loss: 2.8258, Validation Loss: 2.7746\n",
      "Epoch 00063: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best validation loss : 2.7543726783049736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "70it [9:25:02, 332.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 2.11%\n",
      "🔸START - stock_df_1d_ROC_seq120_batch8_hidden64🔸\n",
      "Epoch 20/1000, Train Loss: 2.8410, Validation Loss: 2.8077\n",
      "Epoch 40/1000, Train Loss: 2.7602, Validation Loss: 2.8279\n",
      "Epoch 60/1000, Train Loss: 2.6644, Validation Loss: 2.8379\n",
      "Epoch 00067: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Best validation loss : 2.784348434415357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "71it [9:26:45, 263.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 3.73%\n",
      "🔸START - stock_df_1d_ROC_seq120_batch8_hidden128🔸\n",
      "Epoch 20/1000, Train Loss: 2.8520, Validation Loss: 2.8314\n",
      "Epoch 40/1000, Train Loss: 2.8186, Validation Loss: 2.8144\n",
      "Epoch 60/1000, Train Loss: 2.8203, Validation Loss: 2.7928\n",
      "Epoch 00071: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 80/1000, Train Loss: 2.7748, Validation Loss: 2.7812\n",
      "Epoch 100/1000, Train Loss: 2.7429, Validation Loss: 2.7679\n",
      "Epoch 120/1000, Train Loss: 2.7207, Validation Loss: 2.7619\n",
      "Epoch 140/1000, Train Loss: 2.6794, Validation Loss: 2.7554\n",
      "Epoch 160/1000, Train Loss: 2.6809, Validation Loss: 2.7626\n",
      "Epoch 00165: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Best validation loss : 2.753042529369223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "72it [9:31:13, 476.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 4.22%\n",
      "🔸END🔸\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datanames = ['total_df','stock_df'] # stock_df / total_df\n",
    "TARGETs = [\"Close\",\"1d_ROC\"]                      # \"Close\" / \"1d_ROC\"\n",
    "SEQ_SIZEs = [30,60,120]                         # 30 / 60 / 120\n",
    "PRED_SIZE = 10\n",
    "BATCH_SIZEs = [1,4,8]                        # 1 / 4 / 8\n",
    "HIDDEN_SIZEs = [64,128]                   # 64 / 128\n",
    "\n",
    "for dataname,TARGET,SEQ_SIZE,BATCH_SIZE,HIDDEN_SIZE in tqdm(product(\n",
    "    datanames,TARGETs,SEQ_SIZEs,BATCH_SIZEs,HIDDEN_SIZEs)):\n",
    "    ### Choose dataset & Hyperparameter setting\n",
    "    if datanames=='total_df':\n",
    "        data = total_df\n",
    "    else:\n",
    "        data = stock_df\n",
    "#     TARGET = \"1d_ROC\"                      # \"Close\" / \"1d_ROC\"\n",
    "#     SEQ_SIZE = 60                         # 30 / 60 / 120\n",
    "#     PRED_SIZE = 10\n",
    "#     BATCH_SIZE = 8                        # 1 / 4 / 8\n",
    "#     HIDDEN_SIZE = 64                      # 64 / 128\n",
    "    EPOCHS = 1000\n",
    "    \n",
    "    filename = f'{dataname}_{TARGET}_seq{SEQ_SIZE}_batch{BATCH_SIZE}_hidden{HIDDEN_SIZE}'\n",
    "\n",
    "    print(f'🔸START - {filename}🔸')\n",
    "    ### Make train datset\n",
    "\n",
    "    def split_xy(dataset, time_steps, y_column):\n",
    "        x, y = list(), list()\n",
    "        for i in range(len(dataset)):\n",
    "            x_end_number = i + time_steps\n",
    "            y_end_number = x_end_number + y_column\n",
    "\n",
    "            if y_end_number > len(dataset):\n",
    "                break\n",
    "            tmp_x = dataset.iloc[i:x_end_number, :]  # Adjusted for Pandas\n",
    "            tmp_y = dataset.iloc[x_end_number:y_end_number, :].loc[:, TARGET]\n",
    "            x.append(tmp_x.values)  # Convert to numpy array\n",
    "            y.append(tmp_y.values)  # Convert to numpy array\n",
    "\n",
    "        return np.array(x), np.array(y)\n",
    "\n",
    "    X, y = split_xy(data, SEQ_SIZE, PRED_SIZE)\n",
    "#     print(X[0,:],\"\\n\", y[0])\n",
    "#     print(\"X size : \", X.shape)\n",
    "#     print(\"y size : \", y.shape)\n",
    "\n",
    "    ### Define X_test\n",
    "\n",
    "    X_test = data.tail(SEQ_SIZE).values.reshape(1, SEQ_SIZE, data.shape[1])\n",
    "#     print(X_test)\n",
    "#     print(\"X_test size : \", X_test.shape)\n",
    "\n",
    "    ### Standardization\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    X = X.reshape(X.shape[0], X.shape[1] * X.shape[2])\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    X = X.reshape(X.shape[0], SEQ_SIZE, data.shape[1])\n",
    "\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1] * X_test.shape[2])\n",
    "    X_test = scaler.transform(X_test)\n",
    "    X_test = X_test.reshape(X_test.shape[0], SEQ_SIZE, data.shape[1])\n",
    "\n",
    "#     print(\"X size : \", X.shape)\n",
    "#     print(\"X_test size : \", X_test.shape)\n",
    "\n",
    "    ### Split train-validation dataset\n",
    "\n",
    "    # to DataLoader\n",
    "    import torch\n",
    "    from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state = 1, test_size = 0.2)\n",
    "\n",
    "    # to tensor\n",
    "    X_train = torch.tensor(X_train.astype(np.float32), dtype = torch.float32)\n",
    "    X_valid = torch.tensor(X_valid.astype(np.float32), dtype = torch.float32)\n",
    "    y_train = torch.tensor(y_train.astype(np.float32), dtype = torch.float32)\n",
    "    y_valid = torch.tensor(y_valid.astype(np.float32), dtype = torch.float32)\n",
    "\n",
    "    # to DataLoader\n",
    "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size = BATCH_SIZE, shuffle = True)\n",
    "    val_loader = DataLoader(TensorDataset(X_valid, y_valid), batch_size = BATCH_SIZE, shuffle = False)\n",
    "\n",
    "    ### Initialize Model\n",
    "    try:\n",
    "        for param in model.parameters():\n",
    "            if param.requires_grad:\n",
    "                if len(param.shape) > 1:\n",
    "                    init.xavier_uniform_(param)\n",
    "                else:\n",
    "                    init.zeros_(param)\n",
    "    except:\n",
    "        try:\n",
    "            model.reset_parameters()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    ### Modeling\n",
    "\n",
    "    import copy\n",
    "    class EarlyStopping:\n",
    "        def __init__(self, patience = 5, min_delta = 0, restore_best_weights = True):\n",
    "            self.patience = patience\n",
    "            self.min_delta = min_delta\n",
    "            self.restore_best_weights = restore_best_weights\n",
    "            self.best_model = None\n",
    "            self.best_loss = None\n",
    "            self.counter = 0\n",
    "            self.status = \"\"\n",
    "\n",
    "        def __call__(self, model, val_loss):\n",
    "            if self.best_loss is None:\n",
    "                self.best_loss = val_loss\n",
    "                self.best_model = copy.deepcopy(model.state_dict())\n",
    "            elif self.best_loss - val_loss >= self.min_delta:\n",
    "                self.best_model = copy.deepcopy(model.state_dict())\n",
    "                self.best_loss = val_loss\n",
    "                self.counter = 0\n",
    "                self.status = f\"Improvement found, counter reset to {self.counter}\"\n",
    "            else:\n",
    "                self.counter += 1\n",
    "                self.status = f\"No improvement in the last {self.counter} epochs\"\n",
    "                if self.counter >= self.patience:\n",
    "                    self.status = f\"Early stopping triggered after {self.counter} epochs.\"\n",
    "                    if self.restore_best_weights:\n",
    "                        model.load_state_dict(self.best_model)\n",
    "                    return True\n",
    "            return False\n",
    "\n",
    "    # Positional Encoding for Transformer\n",
    "    class PositionalEncoding(nn.Module):\n",
    "        def __init__(self, d_model, dropout=0.1, max_len=1000):\n",
    "            super(PositionalEncoding, self).__init__()\n",
    "            self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "            pe = torch.zeros(max_len, d_model)\n",
    "            position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "            div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "            pe[:, 0::2] = torch.sin(position * div_term)\n",
    "            pe[:, 1::2] = torch.cos(position * div_term)\n",
    "            pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "            self.register_buffer('pe', pe)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = x + self.pe[:x.size(0), :]\n",
    "            return self.dropout(x)\n",
    "\n",
    "    # Model definition using Transformer\n",
    "    class TransformerModel(nn.Module):\n",
    "        def __init__(self, input_dim, d_model, nhead=4, num_layers=2, dropout=0.2, output_size=10):\n",
    "            super(TransformerModel, self).__init__()\n",
    "\n",
    "            self.encoder = nn.Linear(input_dim, d_model,bias=True)\n",
    "            self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "            encoder_layers = nn.TransformerEncoderLayer(d_model, nhead,bias=True)\n",
    "            self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "            self.decoder = nn.Linear(d_model, output_size,bias=True)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.encoder(x)\n",
    "            x = self.pos_encoder(x)\n",
    "            x = self.transformer_encoder(x)\n",
    "            x = self.decoder(x[:, -1, :])\n",
    "            return x\n",
    "\n",
    "    class RMSELoss(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(RMSELoss,self).__init__()\n",
    "            self.mse = nn.MSELoss()\n",
    "\n",
    "        def forward(self,yhat,y):\n",
    "            return torch.sqrt(self.mse(yhat,y))\n",
    "\n",
    "    model = TransformerModel(X_train.shape[2],\n",
    "                            d_model = HIDDEN_SIZE,\n",
    "                            output_size = PRED_SIZE).to(device)\n",
    "    criterion = RMSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', factor = 0.1, patience = 20, verbose = True)\n",
    "\n",
    "    ### RUN!!\n",
    "\n",
    "    epoch_counter = 0\n",
    "    patience = 30\n",
    "    best_loss = float('inf')\n",
    "    done = False\n",
    "    es = EarlyStopping(patience=patience)\n",
    "    tr_losses_fp, val_losses_fp = [],[]\n",
    "\n",
    "    while not done and epoch_counter<EPOCHS:\n",
    "        epoch_counter+=1\n",
    "\n",
    "        # train\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            x_batch, y_batch = batch\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x_batch)\n",
    "            loss = criterion(output,y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "        train_loss = np.mean(train_losses)\n",
    "        tr_losses_fp.append(train_loss)\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                x_batch, y_batch = batch\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                output = model(x_batch)\n",
    "                loss = criterion(output, y_batch)\n",
    "                val_losses.append(loss.item())\n",
    "        val_loss = np.mean(val_losses)\n",
    "        val_losses_fp.append(val_loss)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if es(model, val_loss):\n",
    "            done = True\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "\n",
    "        if epoch_counter%20 == 0:\n",
    "            print(f\"Epoch {epoch_counter}/{EPOCHS}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "    print(f\"Best validation loss : {best_loss}\")\n",
    "\n",
    "    ### Visualize train-validation loss\n",
    "\n",
    "    plt.plot(range(len(tr_losses_fp)),tr_losses_fp,color='blue',label='train_loss')\n",
    "    plt.plot(range(len(val_losses_fp)),val_losses_fp,color='red',label='val_loss')\n",
    "    plt.legend()\n",
    "    # plt.show()\n",
    "    plt.savefig(f'../../plots/train_val_loss_2/{filename}.png')\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "    ### Prediction\n",
    "\n",
    "    # evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_test = torch.tensor(X_test.astype(np.float32), dtype = torch.float32,device=device)\n",
    "        pred = model(X_test)\n",
    "\n",
    "    pred = pred.to('cpu').detach().numpy()\n",
    "    # print(pred)\n",
    "\n",
    "    if TARGET == \"1d_ROC\" :\n",
    "        endPrice = data['Close'].iloc[-1]\n",
    "        pred_close = []\n",
    "\n",
    "        for i in pred[0] :\n",
    "            endPrice = endPrice + endPrice*0.01*i\n",
    "            pred_close.append(endPrice)\n",
    "\n",
    "        pred = np.array(pred_close).reshape(1, PRED_SIZE)\n",
    "    #     pred\n",
    "    else :\n",
    "        pass\n",
    "\n",
    "    # pred_length = len(np.reshape(pred, (-1)))\n",
    "    # pred_indices = list(range(pred_length))\n",
    "    # plt.plot(pred_indices, np.reshape(pred, (-1)), color='red', alpha=0.6, label='Prediction')\n",
    "    # plt.legend()\n",
    "\n",
    "    # plt.show()\n",
    "\n",
    "    ### Evaluation\n",
    "\n",
    "    # Label\n",
    "    testfile = '../../data/test.csv'\n",
    "    label = pd.read_csv(testfile) # 각자 test.csv 파일 경로\n",
    "    label = np.array(label.head(PRED_SIZE)[\"Close Price\"])\n",
    "\n",
    "    # Prediction\n",
    "    pred = np.array(pred).reshape(PRED_SIZE)\n",
    "\n",
    "    # 날짜 데이터\n",
    "    period = pd.read_csv(testfile)[\"Date\"]\n",
    "    period = [d for d in period.head(PRED_SIZE)]\n",
    "\n",
    "    # 오차율 계산\n",
    "    error_rate = np.abs((label - pred) / label) * 100\n",
    "\n",
    "    # 시각화\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(period, label, marker='o', color='blue', label='Actual Close Price')\n",
    "    plt.plot(period, pred, marker='x', color='red', linestyle='--', label='Predicted Close Price')\n",
    "\n",
    "    # 오차율을 각 포인트에 텍스트로 표시\n",
    "    for date, lbl, prd, err in zip(period, label, pred, error_rate):\n",
    "        plt.text(date, prd, f'{err:.2f}%', color='black', ha='right', va='bottom')\n",
    "\n",
    "    plt.xticks(rotation = 45)  # 날짜 레이블 회전\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Close Price')\n",
    "    plt.title(f'model = LSTM, data = {dataname}, target = {TARGET}, seq_size = {SEQ_SIZE}, pred_size = {PRED_SIZE}, batch_size = {BATCH_SIZE}, model_size = {HIDDEN_SIZE}')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()  # 레이아웃 조정\n",
    "    # plt.show()\n",
    "    plt.savefig(f'../../plots/results_2/{filename}.png')\n",
    "    plt.clf()\n",
    "\n",
    "    # 오차율을 출력\n",
    "    error_rate_dict = dict(zip(period, error_rate))\n",
    "    # error_rate_dict\n",
    "\n",
    "    # 평균 오차율 계산\n",
    "    average_error_rate = np.mean(error_rate)\n",
    "    print(f\"Average Error Rate: {average_error_rate:.2f}%\")\n",
    "\n",
    "    ### Save results to a DataFrame\n",
    "    temp_df = pd.DataFrame({\n",
    "        'data':[dataname],\n",
    "        'target':[TARGET],\n",
    "        'seq_size':[SEQ_SIZE],\n",
    "        'pred_size':[PRED_SIZE],\n",
    "        'batch_size':[BATCH_SIZE],\n",
    "        'hidden_size':[HIDDEN_SIZE],\n",
    "        'best_val_loss':[best_loss],\n",
    "        'mean_error_ratio':[average_error_rate]\n",
    "    })\n",
    "\n",
    "    result_df = pd.concat([result_df,temp_df],axis=0)\n",
    "print('🔸END🔸')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57ada4f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T19:59:52.581060Z",
     "start_time": "2024-02-21T19:59:52.557966Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# result_df = result_df.iloc[1:].reset_index(drop=True)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mresult_df\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../data/final_results_0219.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'result_df' is not defined"
     ]
    }
   ],
   "source": [
    "# result_df = result_df.iloc[1:].reset_index(drop=True)\n",
    "result_df.to_csv('../../data/final_results_0219.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d337cf0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T20:00:50.854479Z",
     "start_time": "2024-02-21T20:00:50.841484Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>target</th>\n",
       "      <th>seq_size</th>\n",
       "      <th>pred_size</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>best_val_loss</th>\n",
       "      <th>mean_error_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>total_df</td>\n",
       "      <td>Close</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>17.283373</td>\n",
       "      <td>7.700228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>total_df</td>\n",
       "      <td>Close</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>17.014774</td>\n",
       "      <td>3.396892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       data target  seq_size  pred_size  batch_size  hidden_size  \\\n",
       "0  total_df  Close        30         10           1           64   \n",
       "1  total_df  Close        30         10           1          128   \n",
       "\n",
       "   best_val_loss  mean_error_ratio  \n",
       "0      17.283373          7.700228  \n",
       "1      17.014774          3.396892  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.read_csv('../../data/final_results_0219.csv',index_col=0)\n",
    "result_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dddd600",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T20:00:50.886489Z",
     "start_time": "2024-02-21T20:00:50.857786Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>target</th>\n",
       "      <th>seq_size</th>\n",
       "      <th>pred_size</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>best_val_loss</th>\n",
       "      <th>mean_error_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>stock_df</td>\n",
       "      <td>Close</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>33.504185</td>\n",
       "      <td>1.431333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>total_df</td>\n",
       "      <td>Close</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>16.852619</td>\n",
       "      <td>1.431409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>total_df</td>\n",
       "      <td>1d_ROC</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>2.548527</td>\n",
       "      <td>1.668213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>stock_df</td>\n",
       "      <td>1d_ROC</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>2.785007</td>\n",
       "      <td>1.697323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>stock_df</td>\n",
       "      <td>1d_ROC</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>2.492974</td>\n",
       "      <td>1.729040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>total_df</td>\n",
       "      <td>Close</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>14.167484</td>\n",
       "      <td>1.743051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>total_df</td>\n",
       "      <td>1d_ROC</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>2.306839</td>\n",
       "      <td>1.750611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>stock_df</td>\n",
       "      <td>1d_ROC</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>2.303385</td>\n",
       "      <td>1.765025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>total_df</td>\n",
       "      <td>1d_ROC</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>2.558942</td>\n",
       "      <td>1.831137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>total_df</td>\n",
       "      <td>Close</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>18.655700</td>\n",
       "      <td>1.908761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>stock_df</td>\n",
       "      <td>1d_ROC</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>2.596930</td>\n",
       "      <td>1.919047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>stock_df</td>\n",
       "      <td>1d_ROC</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>2.564480</td>\n",
       "      <td>1.969334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>total_df</td>\n",
       "      <td>1d_ROC</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>2.327615</td>\n",
       "      <td>1.976633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>total_df</td>\n",
       "      <td>1d_ROC</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>2.565922</td>\n",
       "      <td>1.992590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>stock_df</td>\n",
       "      <td>1d_ROC</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>2.537312</td>\n",
       "      <td>2.035064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>total_df</td>\n",
       "      <td>1d_ROC</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>2.801042</td>\n",
       "      <td>2.055365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>total_df</td>\n",
       "      <td>1d_ROC</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>2.772581</td>\n",
       "      <td>2.062152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>total_df</td>\n",
       "      <td>1d_ROC</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>2.537998</td>\n",
       "      <td>2.065401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>stock_df</td>\n",
       "      <td>1d_ROC</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>2.600813</td>\n",
       "      <td>2.070305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>stock_df</td>\n",
       "      <td>Close</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>40.237464</td>\n",
       "      <td>2.084261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>stock_df</td>\n",
       "      <td>1d_ROC</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>2.754373</td>\n",
       "      <td>2.108023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>stock_df</td>\n",
       "      <td>1d_ROC</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>2.540998</td>\n",
       "      <td>2.172315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>stock_df</td>\n",
       "      <td>1d_ROC</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>2.353260</td>\n",
       "      <td>2.181792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>total_df</td>\n",
       "      <td>1d_ROC</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>2.535277</td>\n",
       "      <td>2.304005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>stock_df</td>\n",
       "      <td>Close</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>17.601029</td>\n",
       "      <td>2.369686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>stock_df</td>\n",
       "      <td>1d_ROC</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>2.861861</td>\n",
       "      <td>2.457833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>total_df</td>\n",
       "      <td>1d_ROC</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>2.784963</td>\n",
       "      <td>2.608600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>total_df</td>\n",
       "      <td>1d_ROC</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>2.611751</td>\n",
       "      <td>2.675151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>stock_df</td>\n",
       "      <td>Close</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>16.945224</td>\n",
       "      <td>2.804927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>stock_df</td>\n",
       "      <td>Close</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>24.866156</td>\n",
       "      <td>3.158526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>total_df</td>\n",
       "      <td>1d_ROC</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>2.576879</td>\n",
       "      <td>3.163018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>total_df</td>\n",
       "      <td>Close</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>15.610622</td>\n",
       "      <td>3.254510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>total_df</td>\n",
       "      <td>1d_ROC</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>2.524482</td>\n",
       "      <td>3.336281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>total_df</td>\n",
       "      <td>Close</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>17.014774</td>\n",
       "      <td>3.396892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>stock_df</td>\n",
       "      <td>1d_ROC</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>2.843964</td>\n",
       "      <td>3.406447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>stock_df</td>\n",
       "      <td>1d_ROC</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>2.784348</td>\n",
       "      <td>3.727092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>stock_df</td>\n",
       "      <td>Close</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>20.800247</td>\n",
       "      <td>3.785211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>stock_df</td>\n",
       "      <td>1d_ROC</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>2.478640</td>\n",
       "      <td>3.867230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>total_df</td>\n",
       "      <td>1d_ROC</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>2.826374</td>\n",
       "      <td>4.024472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>total_df</td>\n",
       "      <td>Close</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>15.432156</td>\n",
       "      <td>4.100361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>stock_df</td>\n",
       "      <td>1d_ROC</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>2.665586</td>\n",
       "      <td>4.158732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>stock_df</td>\n",
       "      <td>1d_ROC</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>2.753043</td>\n",
       "      <td>4.215404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>stock_df</td>\n",
       "      <td>1d_ROC</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>2.585373</td>\n",
       "      <td>4.576493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>stock_df</td>\n",
       "      <td>1d_ROC</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>2.743750</td>\n",
       "      <td>4.675597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>stock_df</td>\n",
       "      <td>Close</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>17.810541</td>\n",
       "      <td>4.734037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>total_df</td>\n",
       "      <td>1d_ROC</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>2.678681</td>\n",
       "      <td>4.783253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>total_df</td>\n",
       "      <td>1d_ROC</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>2.771738</td>\n",
       "      <td>4.809064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>stock_df</td>\n",
       "      <td>Close</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>16.277139</td>\n",
       "      <td>4.842211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>total_df</td>\n",
       "      <td>Close</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>32.504078</td>\n",
       "      <td>4.907623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>stock_df</td>\n",
       "      <td>Close</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>14.590413</td>\n",
       "      <td>5.031411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>stock_df</td>\n",
       "      <td>Close</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>10.861656</td>\n",
       "      <td>5.117800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>total_df</td>\n",
       "      <td>1d_ROC</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>2.841050</td>\n",
       "      <td>5.280077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>total_df</td>\n",
       "      <td>Close</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>15.497323</td>\n",
       "      <td>5.447768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>total_df</td>\n",
       "      <td>1d_ROC</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>2.748022</td>\n",
       "      <td>5.484043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>total_df</td>\n",
       "      <td>Close</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>18.164001</td>\n",
       "      <td>5.608403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>stock_df</td>\n",
       "      <td>Close</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>33.440066</td>\n",
       "      <td>5.987479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>total_df</td>\n",
       "      <td>Close</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>18.890649</td>\n",
       "      <td>6.096274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>total_df</td>\n",
       "      <td>Close</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>17.598565</td>\n",
       "      <td>6.110620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>total_df</td>\n",
       "      <td>Close</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>17.114384</td>\n",
       "      <td>6.535503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>total_df</td>\n",
       "      <td>Close</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>50.852734</td>\n",
       "      <td>7.687947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>total_df</td>\n",
       "      <td>Close</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>17.283373</td>\n",
       "      <td>7.700228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>stock_df</td>\n",
       "      <td>Close</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>16.792566</td>\n",
       "      <td>7.858333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>stock_df</td>\n",
       "      <td>Close</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>18.340511</td>\n",
       "      <td>7.917900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>total_df</td>\n",
       "      <td>Close</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>18.937585</td>\n",
       "      <td>7.930201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>stock_df</td>\n",
       "      <td>Close</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>15.042850</td>\n",
       "      <td>8.083572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>stock_df</td>\n",
       "      <td>Close</td>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>16.425575</td>\n",
       "      <td>8.688491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>stock_df</td>\n",
       "      <td>Close</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>17.177685</td>\n",
       "      <td>13.114186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>total_df</td>\n",
       "      <td>Close</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>45.008694</td>\n",
       "      <td>13.524455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>total_df</td>\n",
       "      <td>Close</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>47.502667</td>\n",
       "      <td>14.088262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>stock_df</td>\n",
       "      <td>Close</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>19.585642</td>\n",
       "      <td>17.145220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>stock_df</td>\n",
       "      <td>Close</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>17.427012</td>\n",
       "      <td>18.945309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>total_df</td>\n",
       "      <td>Close</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>36.820587</td>\n",
       "      <td>31.163834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        data  target  seq_size  pred_size  batch_size  hidden_size  \\\n",
       "51  stock_df   Close       120         10           4          128   \n",
       "16  total_df   Close       120         10           8           64   \n",
       "24  total_df  1d_ROC        60         10           1           64   \n",
       "63  stock_df  1d_ROC        60         10           4          128   \n",
       "66  stock_df  1d_ROC       120         10           1           64   \n",
       "14  total_df   Close       120         10           4           64   \n",
       "18  total_df  1d_ROC        30         10           1           64   \n",
       "54  stock_df  1d_ROC        30         10           1           64   \n",
       "21  total_df  1d_ROC        30         10           4          128   \n",
       "8   total_df   Close        60         10           4           64   \n",
       "61  stock_df  1d_ROC        60         10           1          128   \n",
       "60  stock_df  1d_ROC        60         10           1           64   \n",
       "19  total_df  1d_ROC        30         10           1          128   \n",
       "25  total_df  1d_ROC        60         10           1          128   \n",
       "67  stock_df  1d_ROC       120         10           1          128   \n",
       "27  total_df  1d_ROC        60         10           4          128   \n",
       "33  total_df  1d_ROC       120         10           4          128   \n",
       "31  total_df  1d_ROC       120         10           1          128   \n",
       "59  stock_df  1d_ROC        30         10           8          128   \n",
       "53  stock_df   Close       120         10           8          128   \n",
       "69  stock_df  1d_ROC       120         10           4          128   \n",
       "57  stock_df  1d_ROC        30         10           4          128   \n",
       "55  stock_df  1d_ROC        30         10           1          128   \n",
       "30  total_df  1d_ROC       120         10           1           64   \n",
       "49  stock_df   Close       120         10           1          128   \n",
       "65  stock_df  1d_ROC        60         10           8          128   \n",
       "35  total_df  1d_ROC       120         10           8          128   \n",
       "23  total_df  1d_ROC        30         10           8          128   \n",
       "48  stock_df   Close       120         10           1           64   \n",
       "47  stock_df   Close        60         10           8          128   \n",
       "22  total_df  1d_ROC        30         10           8           64   \n",
       "4   total_df   Close        30         10           8           64   \n",
       "20  total_df  1d_ROC        30         10           4           64   \n",
       "1   total_df   Close        30         10           1          128   \n",
       "64  stock_df  1d_ROC        60         10           8           64   \n",
       "70  stock_df  1d_ROC       120         10           8           64   \n",
       "41  stock_df   Close        30         10           8          128   \n",
       "56  stock_df  1d_ROC        30         10           4           64   \n",
       "29  total_df  1d_ROC        60         10           8          128   \n",
       "10  total_df   Close        60         10           8           64   \n",
       "68  stock_df  1d_ROC       120         10           4           64   \n",
       "71  stock_df  1d_ROC       120         10           8          128   \n",
       "58  stock_df  1d_ROC        30         10           8           64   \n",
       "62  stock_df  1d_ROC        60         10           4           64   \n",
       "42  stock_df   Close        60         10           1           64   \n",
       "32  total_df  1d_ROC       120         10           4           64   \n",
       "34  total_df  1d_ROC       120         10           8           64   \n",
       "46  stock_df   Close        60         10           8           64   \n",
       "5   total_df   Close        30         10           8          128   \n",
       "52  stock_df   Close       120         10           8           64   \n",
       "40  stock_df   Close        30         10           8           64   \n",
       "28  total_df  1d_ROC        60         10           8           64   \n",
       "2   total_df   Close        30         10           4           64   \n",
       "26  total_df  1d_ROC        60         10           4           64   \n",
       "7   total_df   Close        60         10           1          128   \n",
       "45  stock_df   Close        60         10           4          128   \n",
       "6   total_df   Close        60         10           1           64   \n",
       "12  total_df   Close       120         10           1           64   \n",
       "13  total_df   Close       120         10           1          128   \n",
       "15  total_df   Close       120         10           4          128   \n",
       "0   total_df   Close        30         10           1           64   \n",
       "36  stock_df   Close        30         10           1           64   \n",
       "44  stock_df   Close        60         10           4           64   \n",
       "17  total_df   Close       120         10           8          128   \n",
       "38  stock_df   Close        30         10           4           64   \n",
       "50  stock_df   Close       120         10           4           64   \n",
       "37  stock_df   Close        30         10           1          128   \n",
       "3   total_df   Close        30         10           4          128   \n",
       "9   total_df   Close        60         10           4          128   \n",
       "39  stock_df   Close        30         10           4          128   \n",
       "43  stock_df   Close        60         10           1          128   \n",
       "11  total_df   Close        60         10           8          128   \n",
       "\n",
       "    best_val_loss  mean_error_ratio  \n",
       "51      33.504185          1.431333  \n",
       "16      16.852619          1.431409  \n",
       "24       2.548527          1.668213  \n",
       "63       2.785007          1.697323  \n",
       "66       2.492974          1.729040  \n",
       "14      14.167484          1.743051  \n",
       "18       2.306839          1.750611  \n",
       "54       2.303385          1.765025  \n",
       "21       2.558942          1.831137  \n",
       "8       18.655700          1.908761  \n",
       "61       2.596930          1.919047  \n",
       "60       2.564480          1.969334  \n",
       "19       2.327615          1.976633  \n",
       "25       2.565922          1.992590  \n",
       "67       2.537312          2.035064  \n",
       "27       2.801042          2.055365  \n",
       "33       2.772581          2.062152  \n",
       "31       2.537998          2.065401  \n",
       "59       2.600813          2.070305  \n",
       "53      40.237464          2.084261  \n",
       "69       2.754373          2.108023  \n",
       "57       2.540998          2.172315  \n",
       "55       2.353260          2.181792  \n",
       "30       2.535277          2.304005  \n",
       "49      17.601029          2.369686  \n",
       "65       2.861861          2.457833  \n",
       "35       2.784963          2.608600  \n",
       "23       2.611751          2.675151  \n",
       "48      16.945224          2.804927  \n",
       "47      24.866156          3.158526  \n",
       "22       2.576879          3.163018  \n",
       "4       15.610622          3.254510  \n",
       "20       2.524482          3.336281  \n",
       "1       17.014774          3.396892  \n",
       "64       2.843964          3.406447  \n",
       "70       2.784348          3.727092  \n",
       "41      20.800247          3.785211  \n",
       "56       2.478640          3.867230  \n",
       "29       2.826374          4.024472  \n",
       "10      15.432156          4.100361  \n",
       "68       2.665586          4.158732  \n",
       "71       2.753043          4.215404  \n",
       "58       2.585373          4.576493  \n",
       "62       2.743750          4.675597  \n",
       "42      17.810541          4.734037  \n",
       "32       2.678681          4.783253  \n",
       "34       2.771738          4.809064  \n",
       "46      16.277139          4.842211  \n",
       "5       32.504078          4.907623  \n",
       "52      14.590413          5.031411  \n",
       "40      10.861656          5.117800  \n",
       "28       2.841050          5.280077  \n",
       "2       15.497323          5.447768  \n",
       "26       2.748022          5.484043  \n",
       "7       18.164001          5.608403  \n",
       "45      33.440066          5.987479  \n",
       "6       18.890649          6.096274  \n",
       "12      17.598565          6.110620  \n",
       "13      17.114384          6.535503  \n",
       "15      50.852734          7.687947  \n",
       "0       17.283373          7.700228  \n",
       "36      16.792566          7.858333  \n",
       "44      18.340511          7.917900  \n",
       "17      18.937585          7.930201  \n",
       "38      15.042850          8.083572  \n",
       "50      16.425575          8.688491  \n",
       "37      17.177685         13.114186  \n",
       "3       45.008694         13.524455  \n",
       "9       47.502667         14.088262  \n",
       "39      19.585642         17.145220  \n",
       "43      17.427012         18.945309  \n",
       "11      36.820587         31.163834  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.sort_values(by=['mean_error_ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7875ad6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
