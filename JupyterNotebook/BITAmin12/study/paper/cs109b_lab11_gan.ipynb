{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS-109B Advanced Data Science\n",
    "## Lab 11: Generative Adversarial Networks\n",
    "\n",
    "**Harvard University**<br>\n",
    "**Spring 2019**<br>\n",
    "**Lab instructor:** Srivatsan Srinivasan<br>\n",
    "**Instructors:** Pavlos Protopapas and Mark Glickman<br>\n",
    "**Authors:** Srivatsan Srinivasan, Pavlos Protopapas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T14:14:13.540532Z",
     "start_time": "2023-11-05T14:14:11.168207Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "# from keras.datasets import imdb\n",
    "# from keras.models import Sequential, Model\n",
    "# from keras.layers.core import Dense, Dropout\n",
    "# from keras.layers import LSTM, SimpleRNN, Input\n",
    "# from keras.layers.embeddings import Embedding\n",
    "# from keras.layers import Flatten\n",
    "# from keras.preprocessing import sequence\n",
    "# from keras.layers.convolutional import Conv1D\n",
    "# from keras.layers.convolutional import MaxPooling1D\n",
    "# from keras.layers.embeddings import Embedding\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T14:14:25.661414Z",
     "start_time": "2023-11-05T14:14:13.543159Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "np.random.seed(1)\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Goals\n",
    "\n",
    "In this lab we will look at Generative Adversarial Networks (GANs), their construction and training.\n",
    "\n",
    "By the end of this lab, you should:\n",
    "\n",
    "- know how to put together the building blocks used in GANs \n",
    "- have a good undertanding of generative models and implicit distributions that generators learn\n",
    "- learning properties of GAN at a small scale\n",
    "- concepts of adversarial training - min-max etc.\n",
    "- mode collapse problems in GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE 1 : Generate 1-D Gaussian Distribution from Uniform Noise\n",
    "\n",
    "In this exercise, we are going to generate 1-D Gaussian distribution from a n-D uniform distribution. This is a toy exercise in order to understand the ability of GANs (generators) to generate arbitrary distributions from random noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate training data - Gaussian Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T14:14:25.684728Z",
     "start_time": "2023-11-05T14:14:25.661414Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_data(n_samples = 10000,n_dim=1):\n",
    "  return np.random.randn(n_samples, n_dim)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define a function that gives you a keras model of general feedforward network \n",
    "based on the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUT is of input dim,, goes through n_layers number of hidden layers and output is of output_dim\n",
    "def set_model(input_dim, output_dim, hidden_dim=64,n_layers = 1,activation='tanh',\n",
    "              optimizer='adam', loss = 'binary_crossentropy'):\n",
    "    #### YOUR CODE HERE ####\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T03:20:10.023884Z",
     "start_time": "2023-10-29T03:20:09.995832Z"
    }
   },
   "outputs": [],
   "source": [
    "class FeedForwardNet(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim=64, n_layers=1):\n",
    "        super(Model, self).__init__()\n",
    "        self.input_dim = imput_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.tanh(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUT (z) is of random_dim dimension \n",
    "#OUTPUT should be a keras model - D(G(z)) - \n",
    "# Discriminator score for the generator's images generated\n",
    "#from synthetic data.\n",
    "\n",
    "def get_gan_network(discriminator, random_dim, generator, optimizer = 'adam'):\n",
    "    ### YOUR CODE HERE ###\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T00:23:17.486002Z",
     "start_time": "2023-10-29T00:23:17.462972Z"
    }
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, random_dim,output_dim, hidden_dim = 64 ):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc1 = nn.Linear(random_dim, hidden_dim, bias=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim, bias=True)\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.tanh(self.fc2(x))\n",
    "        return x        \n",
    "        \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim, bias=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim,output_dim, bias=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x        \n",
    "\n",
    "def get_gan_network(discriminator, random_dim, generator):\n",
    "    return discriminator(generator(random_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now write the training function for a GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T00:23:19.204410Z",
     "start_time": "2023-10-29T00:23:19.187102Z"
    }
   },
   "outputs": [],
   "source": [
    "NOISE_DIM = 10\n",
    "DATA_DIM = 1\n",
    "G_LAYERS = 1\n",
    "D_LAYERS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T00:23:19.953199Z",
     "start_time": "2023-10-29T00:23:19.913365Z"
    }
   },
   "outputs": [],
   "source": [
    "generator = Generator(NOISE_DIM,DATA_DIM,64)\n",
    "discriminator = Discriminator(DATA_DIM, 1, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T00:23:20.814861Z",
     "start_time": "2023-10-29T00:23:20.794820Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion_g = nn.MSELoss()\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=0.001, betas=[0.5,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T00:23:23.560794Z",
     "start_time": "2023-10-29T00:23:23.536773Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "non-default argument follows default argument (2092871023.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[71], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    def train_gan(epochs=1,batch_size=128, generator, discriminator):\u001b[0m\n\u001b[1;37m                                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m non-default argument follows default argument\n"
     ]
    }
   ],
   "source": [
    "def train_gan(generator, discriminator, epochs=1,batch_size=128):\n",
    "  x_train = generate_data(n_samples=12800,n_dim=DATA_DIM)\n",
    "  batch_count = x_train.shape[0]/batch_size\n",
    "  \n",
    "#   generator = set_model(NOISE_DIM, # input\n",
    "#                         DATA_DIM,  # output\n",
    "#                         n_layers=G_LAYERS, \n",
    "#                         activation='tanh',loss = 'mean_squared_error')\n",
    "#   discriminator = set_model(DATA_DIM, # input\n",
    "#                             1, # output\n",
    "#                             n_layers= D_LAYERS, activation='sigmoid')\n",
    "\n",
    "\n",
    "    gan = get_gan_network(discriminator, NOISE_DIM, generator)\n",
    "  \n",
    "  for e in range(1,epochs+1):   \n",
    "    \n",
    "    # Noise is generated from a uniform distribution\n",
    "    noise = np.random.rand(batch_size,NOISE_DIM)\n",
    "    true_batch = x_train[np.random.choice(x_train.shape[0], batch_size, replace=False), :]\n",
    "    \n",
    "    generated_values = generator.predict(noise)\n",
    "    X = np.concatenate([generated_values,true_batch])\n",
    "    \n",
    "    y_dis = np.zeros(2*batch_size)\n",
    "    \n",
    "    #One-sided label smoothing to avoid overconfidence. In GAN, if the discriminator depends on a small set of features to detect real images, \n",
    "    #the generator may just produce these features only to exploit the discriminator. \n",
    "    #The optimization may turn too greedy and produces no long term benefit.\n",
    "    #To avoid the problem, we penalize the discriminator when the prediction for any real images go beyond 0.9 (D(real image)>0.9). \n",
    "    y_dis[:batch_size] = 0.9    \n",
    "    \n",
    "    discriminator.trainable = True  \n",
    "    ###YOUR CODE HERE####\n",
    "    # One line : Train discriminator using train_on_batch  \n",
    "    discriminator.trainable = False\n",
    "\n",
    "    # Train generator. Noise is generated from a uniform distribution\n",
    "    ### YOUR CODE HERE. Couple of lines. Should call gan.train_on_batch()###\n",
    " \n",
    " \n",
    "    \n",
    "  return generator, discriminator\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator, discriminator = train_gan()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us visualize what the generator has learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.random.rand(10000,NOISE_DIM)\n",
    "generated_values = generator.predict(noise)\n",
    "plt.hist(generated_values,bins=100)\n",
    "\n",
    "\n",
    "true_gaussian = [np.random.randn() for x in range(10000)]\n",
    "\n",
    "print('1st order moment - ', 'True : ', scipy.stats.moment(true_gaussian, 1) , ', GAN :', scipy.stats.moment(generated_values,1))\n",
    "print('2nd order moment - ', 'True : ', scipy.stats.moment(true_gaussian, 2) , ', GAN :', scipy.stats.moment(generated_values,2))\n",
    "print('3rd order moment - ', 'True : ', scipy.stats.moment(true_gaussian, 3) , ', GAN :', scipy.stats.moment(generated_values,3))\n",
    "print('4th order moment - ', 'True : ', scipy.stats.moment(true_gaussian, 4) , ', GAN :', scipy.stats.moment(generated_values,4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CONCLUSIONS\n",
    "\n",
    "1. GANs are able to learn a generative model from arbitrary noise distributions.\n",
    "\n",
    "2. Traditional GANs do not learn the higher-order moments well. Possible issues : Number of samples, approximating higher moments is hard. Usually known to under-predict higher order variances. For people interested in learning why, read more about divergence measures between distributions (particularly about Wasserstein etc.)\n",
    "\n",
    "#### PLAY WITH IT WHEN YOU HAVE TIME !\n",
    "\n",
    "1. Try different noise dimensions and see what minimum dimension you need to learn this well.\n",
    "2. Try to generate multimodal distribution like a Gaussian Mixture instead of simple Gaussian and see if GAN is able to learn multimodal distributions well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE 2 : MNIST GAN - Learn to generate MNIST digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T19:47:57.458027Z",
     "start_time": "2023-11-05T19:47:57.415444Z"
    }
   },
   "outputs": [],
   "source": [
    "# from keras.datasets import mnist\n",
    "# from keras.utils import np_utils\n",
    "# from keras.models import Sequential, Model\n",
    "# from keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
    "# from keras.layers.advanced_activations import LeakyReLU\n",
    "# from keras.optimizers import Adam, RMSprop\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "# Dataset of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images.\n",
    "# (X_train, Y_train), (X_test, Y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rescale data since we are using ReLU activations. <b>WHY ?</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T03:20:24.222208Z",
     "start_time": "2023-10-29T03:20:24.205820Z"
    }
   },
   "outputs": [],
   "source": [
    "# X_train = X_train.reshape(60000, 784)\n",
    "# X_test = X_test.reshape(10000, 784)\n",
    "# X_train = X_train.astype('float32')/255\n",
    "# X_test = X_test.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T19:48:01.316035Z",
     "start_time": "2023-11-05T19:48:01.285591Z"
    }
   },
   "outputs": [],
   "source": [
    "z_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T19:48:07.154658Z",
     "start_time": "2023-11-05T19:48:05.504673Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: dataset\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "mnist_dataset = datasets.MNIST('dataset', train=True, download=True, \n",
    "               transform=transforms.Compose([\n",
    "                   transforms.ToTensor()\n",
    "]))\n",
    "mnist_dataset_test  = datasets.MNIST('dataset', train=False, download=True, \n",
    "               transform=transforms.Compose([\n",
    "                   transforms.ToTensor()\n",
    "]))\n",
    "mnist_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T19:48:13.093744Z",
     "start_time": "2023-11-05T19:48:13.077493Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(mnist_dataset,batch_size=128)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_dataset_test,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T14:15:52.542164Z",
     "start_time": "2023-10-28T14:15:52.534685Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T19:48:15.308211Z",
     "start_time": "2023-11-05T19:48:15.236669Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 1, 28, 28]), torch.Size([1, 28, 28]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "images.size(),images[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-05T19:48:16.669049Z",
     "start_time": "2023-11-05T19:48:16.661523Z"
    }
   },
   "outputs": [],
   "source": [
    "def reduce_batch(images):\n",
    "    # image.shape = [128,1,28,28]\n",
    "    return images.squeeze().flatten(1,2)/255 # [128, 784]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BUILD MODEL\n",
    "\n",
    "We are using LeakyReLU activations. \n",
    "\n",
    "We will build\n",
    "\n",
    "a.) Generator\n",
    "b.) Discriminator\n",
    "c.) GAN\n",
    "\n",
    "as feedforwards with multiple layers, dropout and LeakyReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T00:57:29.894885Z",
     "start_time": "2023-11-06T00:57:29.876876Z"
    }
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "# adam = Adam(lr=0.0002, beta_1=0.5)\n",
    "\n",
    "#GENERATOR\n",
    "# g = Sequential()\n",
    "#Build your generator - noise_dim -> 256 -> 512 ->1024 ->784. LeakyRelU(0.2), adam\n",
    "###YOUR CODE HERE###\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dims, momentum=0.8):\n",
    "        super(Generator, self).__init__()\n",
    "        self.latent_dims = latent_dims\n",
    "        \n",
    "        self.fc1 = nn.Linear(latent_dims, 128)\n",
    "        self.fc1_bn = nn.BatchNorm1d(128, momentum=momentum)\n",
    "        \n",
    "        self.fc2 = nn.Linear(128, 256)\n",
    "        self.fc2_bn = nn.BatchNorm1d(256, momentum=momentum)\n",
    "        \n",
    "        self.fc3 = nn.Linear(256, 512)\n",
    "        self.fc3_bn = nn.BatchNorm1d(512, momentum=momentum)\n",
    "        \n",
    "        self.fc4 = nn.Linear(512, 1024)\n",
    "        self.fc4_bn = nn.BatchNorm1d(1024, momentum=momentum)\n",
    "        \n",
    "        self.fc5 = nn.Linear(1024, 784)\n",
    "\n",
    "\n",
    "    def forward(self, z):\n",
    "        z = self.fc1_bn(F.leaky_relu(self.fc1(z), negative_slope=0.2))\n",
    "        z = self.fc2_bn(F.leaky_relu(self.fc2(z), negative_slope=0.2))\n",
    "        z = self.fc3_bn(F.leaky_relu(self.fc3(z), negative_slope=0.2))\n",
    "        z = self.fc4_bn(F.leaky_relu(self.fc4(z), negative_slope=0.2))\n",
    "        z = self.fc5(z)\n",
    "        print('G(z).size() :',z.size())\n",
    "        return z     \n",
    "\n",
    "#DISCRIMINATOR\n",
    "#Build your discriminator - 784 -> 1024 -> 512 -> 256 -> 1. LeakyRelu(0.2), adam\n",
    "# d = Sequential()\n",
    "###YOUR CODE HERE###\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc1(x), negative_slope=0.2)\n",
    "        x = F.leaky_relu(self.fc2(x), negative_slope=0.2)\n",
    "        x = self.fc3(x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T00:57:30.421998Z",
     "start_time": "2023-11-06T00:57:30.397199Z"
    }
   },
   "outputs": [],
   "source": [
    "#GAN\n",
    "# d.trainable = False\n",
    "# inputs = Input(shape=(z_dim, ))\n",
    "# hidden = g(inputs)\n",
    "\n",
    "generator = Generator(z_dim)\n",
    "discriminator = Discriminator()\n",
    "criterion = nn.BCELoss()\n",
    "discriminator_optim = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5,0.999))\n",
    "generator_optim = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5,0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T00:57:31.169883Z",
     "start_time": "2023-11-06T00:57:31.151876Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATOR :  Generator(\n",
      "  (fc1): Linear(in_features=100, out_features=128, bias=True)\n",
      "  (fc1_bn): BatchNorm1d(128, eps=1e-05, momentum=0.8, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=128, out_features=256, bias=True)\n",
      "  (fc2_bn): BatchNorm1d(256, eps=1e-05, momentum=0.8, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=256, out_features=512, bias=True)\n",
      "  (fc3_bn): BatchNorm1d(512, eps=1e-05, momentum=0.8, affine=True, track_running_stats=True)\n",
      "  (fc4): Linear(in_features=512, out_features=1024, bias=True)\n",
      "  (fc4_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.8, affine=True, track_running_stats=True)\n",
      "  (fc5): Linear(in_features=1024, out_features=784, bias=True)\n",
      ")\n",
      "DISCRIMINATOR :  Discriminator(\n",
      "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"GENERATOR : \", generator)\n",
    "print(\"DISCRIMINATOR : \", discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T00:57:32.182988Z",
     "start_time": "2023-11-06T00:57:32.169003Z"
    }
   },
   "outputs": [],
   "source": [
    "# hidden = generator_()\n",
    "\n",
    "# class GAN_(nn.Module):\n",
    "#     def __init__(self, generator, discriminator):\n",
    "#         super(GAN_, self).__init__()\n",
    "#         self.g = generator\n",
    "#         self.d = discriminator\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         out = self.g(x)\n",
    "#         out = self.d(out)\n",
    "#         return out\n",
    "        \n",
    "# gan = GAN_(generator_, discriminator_)\n",
    "# criterion_gan = nn.BCELoss()\n",
    "# optimizer_gan = optim.Adam(gan.parameters(),lr=0.0002, betas=(0.5,0.999))\n",
    "\n",
    "# output = d(hidden)\n",
    "# gan = Model(inputs, output)\n",
    "# gan.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us write some visualization code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T00:57:33.103112Z",
     "start_time": "2023-11-06T00:57:33.083698Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_loss(losses):\n",
    "    \"\"\"\n",
    "    @losses.keys():\n",
    "        0: loss\n",
    "        1: accuracy\n",
    "    \"\"\"\n",
    "    d_loss = [v[0] for v in losses[\"D\"]]\n",
    "    g_loss = [v[0] for v in losses[\"G\"]]\n",
    "    \n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(d_loss, label=\"Discriminator loss\")\n",
    "    plt.plot(g_loss, label=\"Generator loss\")\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_generated(n_ex=10, dim=(1, 10), figsize=(12, 2)):\n",
    "    noise = np.random.normal(0, 1, size=(n_ex, z_dim))\n",
    "    generated_images = g.predict(noise)\n",
    "    generated_images = generated_images.reshape(n_ex, 28, 28)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(dim[0], dim[1], i+1)\n",
    "        plt.imshow(generated_images[i], interpolation='nearest', cmap='gray_r')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> TRAIN THE MODEL </b>\n",
    "\n",
    "Generate noise, feed into generator, compare them with discriminator, train the GAN and REPEAT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T00:57:33.977199Z",
     "start_time": "2023-11-06T00:57:33.962986Z"
    }
   },
   "outputs": [],
   "source": [
    "losses = {\"D\":[], \"G\":[]}\n",
    "\n",
    "def train(generator, discriminator, gen_optimizer, dis_optimizer,\n",
    "          criterion, train_loader, epochs=1, plt_frq=1, BATCH_SIZE=128):\n",
    "#     batchCount = int(X_train.shape[0] / BATCH_SIZE)\n",
    "    batchCount = int(len(train_loader.dataset) / BATCH_SIZE)\n",
    "    print('Epochs:', epochs)\n",
    "    print('Batch size:', BATCH_SIZE)\n",
    "    print('Batches per epoch:', batchCount)\n",
    "    \n",
    "#     testing_random_latent = torch.randn(5, z_dim)\n",
    "    \n",
    "#     for e in range(1, epochs+1):\n",
    "#         if e == 1 or e%plt_frq == 0:\n",
    "#             print('-'*15, 'Epoch %d' % e, '-'*15)\n",
    "#         for batch_index, (batch_images, _) in enumerate(train_loader):\n",
    "            \n",
    "# #             batch_images.size() == (128,1,28,28)\n",
    "#             batch_images = batch_images.view(BATCH_SIZE, -1) # (128, 784)\n",
    "# #             print(batch_x.size(0))\n",
    "#             reals = torch.ones(BATCH_SIZE,1)\n",
    "#             fakes = torch.zeros(BATCH_SIZE,1)\n",
    "            \n",
    "#             # discriminator  ### >> D(x) 부분\n",
    "#             dis_results = discriminator(batch_images) # train real images\n",
    "#             # dis_results.size() = (BATCH_SIZE,1,1)\n",
    "#             dis_real_loss = criterion(dis_results, reals) # discriminator에게 real distribution을 학습\n",
    "# #             dis_results = dis_results.view(-1,1)  # ((BATCH_SIZE,1))\n",
    "            \n",
    "                        \n",
    "#             # Generator  ### >> D(G(z)) 부분\n",
    "#             latent = torch.randn(BATCH_SIZE, z_dim) # random variable z\n",
    "#             fake_images = generator(latent).detach() # generate fake image = G(z)\n",
    "# #             print('fake_image:',fake_images.size())\n",
    "#             dis_results = discriminator(fake_images) # D(G(z)) 부분\n",
    "            \n",
    "# #             print(dis_results)\n",
    "# #             print('fakes:',fakes)\n",
    "        \n",
    "#             dis_fake_loss = criterion(dis_results, fakes) # D로 하여금 G가 가짜임을 학습시킴\n",
    "            \n",
    "#             # total loss = E[log(D(x))] + E[log(1-(D(G(z))))]\n",
    "#             dis_total_loss = dis_real_loss + dis_fake_loss\n",
    "            \n",
    "#             # 역전파 >> D 모델 가중치 갱신\n",
    "#             discriminator.zero_grad() \n",
    "#             dis_total_loss.backward() \n",
    "#             dis_optimizer.step()\n",
    "            \n",
    "#             # G로 하여금 다시 D를 속일 수 있게 만들어야 함\n",
    "#             latent = torch.randn(BATCH_SIZE, z_dim)\n",
    "#             fake_images = generator(latent)\n",
    "#             dis_results = discriminator(fake_images) \n",
    "            \n",
    "#             # D 스텝이 끝난 후 G 수정\n",
    "#             gen_loss = criterion(dis_results,reals) # E[log(1-(D(G(z))))]\n",
    "            \n",
    "#             # 역전파, 최적화\n",
    "#             discriminator.zero_grad()\n",
    "#             generator.zero_grad()\n",
    "#             gen_loss.backward()\n",
    "#             gen_optimizer.step()\n",
    "            \n",
    "            \n",
    "#     if epoch % 20 == 0:\n",
    "# #             print(\"EPOCH {}: BATCH: {}, discrim_loss: {}, generator_loss: {}\".format(epoch, batch_index, dis_total_loss, gen_loss))\n",
    "#         with torch.no_grad():\n",
    "#             testing_fake_images = generator(testing_random_latent)\n",
    "#             testing_fake_images = testing_fake_images.reshape(5, 28, 28).numpy()\n",
    "\n",
    "#             plt.figure(figsize=(10, 5))\n",
    "#             plt.title(\"GENERATED IMAGE, EPOCH {}\".format(epoch))\n",
    "#             for i in range(5):\n",
    "#                 plt.subplot('15{}'.format(i+1))\n",
    "#                 plt.imshow(testing_fake_images[i], cmap='gray')\n",
    "#             plt.show()\n",
    "\n",
    "#     return discriminator, generator\n",
    "            \n",
    "    batch_size = BATCH_SIZE\n",
    "    testing_random_latent = torch.randn(5, z_dim)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for batch_index, (batch_images, _) in enumerate(train_loader):\n",
    "            # Label 생성\n",
    "            reals = torch.ones(batch_size, 1)\n",
    "            fakes = torch.zeros(batch_size, 1)\n",
    "\n",
    "            batch_images = batch_images.view(batch_size, -1)\n",
    "            \n",
    "            #### DISCRIMINATOR\n",
    "            # Real Image 에 대한 loss\n",
    "            dis_results = discriminator(batch_images)\n",
    "            dis_real_loss = criterion(dis_results, reals)\n",
    "            \n",
    "            # Fake Image 에 대한 loss\n",
    "            latent = torch.randn(batch_size, z_dim)\n",
    "            fake_images = generator(latent).detach()\n",
    "            dis_results = discriminator(fake_images)\n",
    "            dis_fake_loss = criterion(dis_results, fakes)\n",
    "            \n",
    "            # total loss\n",
    "            dis_total_loss = dis_real_loss + dis_fake_loss\n",
    "\n",
    "            discriminator.zero_grad()\n",
    "            dis_total_loss.backward()\n",
    "            dis_optimizer.step()\n",
    "            \n",
    "\n",
    "            #### GENERATOR\n",
    "            latent = torch.randn(batch_size, z_dim)\n",
    "            fake_images = generator(latent) \n",
    "            dis_results = discriminator(fake_images)\n",
    "            \n",
    "            # Fake Image 에 대한 generator loss\n",
    "            # 여기가 매우 중요, 우리가 generator 를 train 할 때는, log(1-D(G(z)))를 최소화 하기로 하였다.\n",
    "            # 하지만, -log(D(G(z)))를 최소화 한다면, 원 식의 방향과 같은 방향으로 최적화가 된다.\n",
    "            # 이는 log(1-x) 식이 그 기울기가 매우 작기 때문에, 매우 오래 걸리는 것을 보완하기 위함이다.\n",
    "            # 그리고 -log(D(G(z)))의 최소화는 log(D(G(z)))의 최대화와 같다.\n",
    "            gen_loss = criterion(dis_results, reals)\n",
    "            \n",
    "            discriminator.zero_grad()\n",
    "            generator.zero_grad()\n",
    "            gen_loss.backward()\n",
    "            gen_optimizer.step()\n",
    "            \n",
    "\n",
    "        if epoch % 20 == 0:\n",
    "            print(\"EPOCH {}: BATCH: {}, discrim_loss: {}, generator_loss: {}\".format(epoch, batch_index, dis_total_loss, gen_loss))\n",
    "            with torch.no_grad():\n",
    "                testing_fake_images = generator(testing_random_latent)\n",
    "                testing_fake_images = testing_fake_images.reshape(5, 28, 28).numpy()\n",
    "                \n",
    "                plt.figure(figsize=(10, 5))\n",
    "                plt.title(\"GENERATED IMAGE, EPOCH {}\".format(epoch))\n",
    "                for i in range(5):\n",
    "                   plt.subplot('15{}'.format(i+1))\n",
    "                   plt.imshow(testing_fake_images[i], cmap='gray')\n",
    "                plt.show()\n",
    "            \n",
    "    return discriminator, generator\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T00:58:11.179282Z",
     "start_time": "2023-11-06T00:57:34.656151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 200\n",
      "Batch size: 128\n",
      "Batches per epoch: 468\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n",
      "G(z).size() : torch.Size([128, 784])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (128x588 and 784x256)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[92], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminator_optim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator_optim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplt_frq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[91], line 93\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(generator, discriminator, gen_optimizer, dis_optimizer, criterion, train_loader, epochs, plt_frq, BATCH_SIZE)\u001b[0m\n\u001b[0;32m     89\u001b[0m batch_images \u001b[38;5;241m=\u001b[39m batch_images\u001b[38;5;241m.\u001b[39mview(batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m#### DISCRIMINATOR\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# Real Image 에 대한 loss\u001b[39;00m\n\u001b[1;32m---> 93\u001b[0m dis_results \u001b[38;5;241m=\u001b[39m \u001b[43mdiscriminator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_images\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m dis_real_loss \u001b[38;5;241m=\u001b[39m criterion(dis_results, reals)\n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m# Fake Image 에 대한 loss\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[86], line 49\u001b[0m, in \u001b[0;36mDiscriminator.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 49\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mleaky_relu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m, negative_slope\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[0;32m     50\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mleaky_relu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x), negative_slope\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[0;32m     51\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc3(x)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py39\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (128x588 and 784x256)"
     ]
    }
   ],
   "source": [
    "train(generator, discriminator, discriminator_optim, generator_optim, \n",
    "      criterion, train_loader, epochs=200, plt_frq=40, BATCH_SIZE=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TAKE-HOME EXERCISE\n",
    "\n",
    "1. Try to build CNN models instead of feedforwards\n",
    "2. Try different noise dimensions\n",
    "3. Try implementing some training tricks suggested in https://github.com/soumith/ganhacks and study incremental improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DISCUSSION : Why can GANs potentially mode collapse ? Remember there is no guarantee of mode collapse.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TL;DR - There is inherently no \"motivation\" for generator to produce a diverse set of samples as discriminator only penalizes for producing \"bad\" samples. It is easy to learn a few modes than all modes of a multi modal distribution.\n",
    "\n",
    "Remember, the goal of the generator G is to fool the discriminator by causing it to assign the generated sample the highest probability of being real as possible. Mathematically, G tries to minimize E_z∼p_z(z)[log(1−D(G(z)))], or in other words, to generate the point x*=G(z) such that x*=argmax_x D(x) (of course, we’re assuming that we hold the discriminator fixed for now; we’re merely describing the optimization objective at a given timestep). Note that this x* is fixed regardless of the value of z, the input to the generator! x* only depends on the discriminator at the given timestep. This means that on expectation, there exists a single fixed point that the generator thinks is the most optimal point to generate regardless of whatever input noise we feed it - there is nothing in the objective function that explicitly forces the generator to generate different samples given the input. During this training step, stochastic gradient descent - again, on expectation - would cause the generator to update its weights towards generating this ideal point.\n",
    "\n",
    "This by itself doesn’t immediately mean mode collapse; during the entirety of the training process, mode collapse may happen only partially or not at all. Since training is a stochastic process, during the beginning stages in training the generated samples will vary depending on z and the samples drawn from the real distribution will also vary - this means that gradients backpropagated to the generator will vary between training steps depending on the generated and real samples. Moreover the discriminator, ideally, should be able to identify generator mode collapse while it’s happening and assign the collapse point a low probability to force the generator to spread out. This is why we do see training runs succeed in GAN/DCGAN-based models.\n",
    "\n",
    "But in practice, especially in default GAN models, mode collapse happens quite often. The discriminator ends up not really forcing more diversity in the generator, so much as simply pushing the partially collapsed generator to a different part of output space - if it assigns the collapse point a low probability, the generator will simply move its collapsed distribution to focus on a new output point. And finally, in the case where the generator has actually collapsed to a single point, it can’t get out; you’ll have to restart your training. To see why this is the case, remember how I said above that the gradient updates to the generator are stochastic, because its generated outputs will vary based on z. Well, in the world where the generator is already collapsed, it will emit the same output for every z. This means that if you feed a batch of generator outputs to the discriminator and get the gradients back, the generator gradients will all essentially be identical. And they’ll all be racing towards the same maximum point x*! Which means the generator will continue to generate the same output regardless of input. Even if the discriminator identifies this and sets the point to low probability, still, the identical gradient updates will cause all outputs of the generator rushing to another fixed point. At this point your training is ruined.\n",
    "\n",
    "\n",
    "Thanks : This version of the answer is from https://www.quora.com/What-causes-mode-collapse-in-GANs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
